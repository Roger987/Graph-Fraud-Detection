{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import random\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234355/234355 [00:04<00:00, 56936.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  1.6305e-01,  1.9638e+00,  ..., -6.9424e-01,\n",
      "          2.0847e+00,  2.5308e-02],\n",
      "        [ 1.0000e+00, -5.0271e-03,  5.7894e-01,  ..., -6.9424e-01,\n",
      "          2.0847e+00,  2.5308e-02],\n",
      "        [ 1.0000e+00, -1.4785e-01, -1.8467e-01,  ..., -6.3365e-01,\n",
      "         -6.7628e-01, -1.0849e+00],\n",
      "        ...,\n",
      "        [ 4.9000e+01, -1.7041e-01, -7.8164e-02,  ..., -6.9399e-01,\n",
      "         -7.2078e-01, -1.0849e+00],\n",
      "        [ 4.9000e+01, -9.3732e-02, -1.1616e-01,  ...,  1.7883e+00,\n",
      "          1.8226e+00,  1.1355e+00],\n",
      "        [ 4.9000e+01, -1.7201e-01, -7.8182e-02,  ..., -5.2008e-01,\n",
      "         -5.9215e-01,  1.1355e+00]])\n",
      "Max edge index: 203768\n",
      "Number of nodes: 46564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "\n",
    "# Preprocess the classes DataFrame\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))\n",
    "\n",
    "# Filter out 'unknown' labels\n",
    "df_filtered = df[df['label'] != 'unknown']\n",
    "filtered_classes = classes[classes['label'] != 'unknown']\n",
    "\n",
    "filtered_edges_dict = {tx_id: i for i, tx_id in enumerate(filtered_classes['txId'])}\n",
    "\n",
    "filtered_edges_list = [\n",
    "    (filtered_edges_dict[edges['txId1'][i]], filtered_edges_dict[edges['txId2'][i]])\n",
    "    for i in tqdm(range(len(edges)))\n",
    "    if edges['txId1'][i] in filtered_classes['txId'].values and\n",
    "       edges['txId2'][i] in filtered_classes['txId'].values\n",
    "]\n",
    "filtered_edge_index = torch.tensor(filtered_edges_list, dtype=torch.long).T\n",
    "\n",
    "# Convert node features and labels    Parameter to (V) choose features used\n",
    "node_features = torch.tensor(df_filtered.iloc[:, 1:94].values, dtype=torch.float)\n",
    "#edge_index = torch.tensor(filtered_edges_list.values.T, dtype=torch.int64)\n",
    "label_mapping = {'1': 0, '2': 1} \n",
    "labels = torch.tensor(filtered_classes['label'].map(label_mapping).values, dtype=torch.long)\n",
    "\n",
    "# Create graph data object\n",
    "data = Data(x=node_features, edge_index=filtered_edge_index, y=labels)\n",
    "print(node_features)\n",
    "edges = pd.read_csv(edges_path)\n",
    "\n",
    "# Check the maximum index in the edges\n",
    "print(f\"Max edge index: {edges.max().max()}\")\n",
    "print(f\"Number of nodes: {len(node_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gcn): GCNConv(93, 128)\n",
      "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Epoch   0 | Loss: 2.78 | Acc: 10.01%\n",
      "Epoch   1 | Loss: 0.55 | Acc: 90.23%\n",
      "Epoch   2 | Loss: 0.91 | Acc: 90.24%\n",
      "Epoch   3 | Loss: 1.07 | Acc: 90.24%\n",
      "Epoch   4 | Loss: 1.08 | Acc: 90.24%\n",
      "Epoch   5 | Loss: 1.02 | Acc: 90.24%\n",
      "Epoch   6 | Loss: 0.92 | Acc: 90.24%\n",
      "Epoch   7 | Loss: 0.80 | Acc: 90.24%\n",
      "Epoch   8 | Loss: 0.69 | Acc: 90.24%\n",
      "Epoch   9 | Loss: 0.59 | Acc: 90.24%\n",
      "Epoch  10 | Loss: 0.49 | Acc: 90.24%\n",
      "Epoch  11 | Loss: 0.42 | Acc: 90.24%\n",
      "Epoch  12 | Loss: 0.37 | Acc: 90.24%\n",
      "Epoch  13 | Loss: 0.33 | Acc: 90.24%\n",
      "Epoch  14 | Loss: 0.31 | Acc: 90.27%\n",
      "Epoch  15 | Loss: 0.29 | Acc: 90.28%\n",
      "Epoch  16 | Loss: 0.28 | Acc: 90.25%\n",
      "Epoch  17 | Loss: 0.27 | Acc: 90.24%\n",
      "Epoch  18 | Loss: 0.26 | Acc: 90.25%\n",
      "Epoch  19 | Loss: 0.25 | Acc: 90.25%\n",
      "Epoch  20 | Loss: 0.24 | Acc: 90.25%\n",
      "Epoch  21 | Loss: 0.23 | Acc: 90.28%\n",
      "Epoch  22 | Loss: 0.23 | Acc: 90.31%\n",
      "Epoch  23 | Loss: 0.22 | Acc: 90.31%\n",
      "Epoch  24 | Loss: 0.22 | Acc: 90.30%\n",
      "Epoch  25 | Loss: 0.21 | Acc: 90.31%\n",
      "Epoch  26 | Loss: 0.21 | Acc: 90.31%\n",
      "Epoch  27 | Loss: 0.20 | Acc: 90.40%\n",
      "Epoch  28 | Loss: 0.20 | Acc: 90.49%\n",
      "Epoch  29 | Loss: 0.20 | Acc: 91.97%\n",
      "Epoch  30 | Loss: 0.19 | Acc: 91.96%\n",
      "Epoch  31 | Loss: 0.19 | Acc: 91.93%\n",
      "Epoch  32 | Loss: 0.19 | Acc: 91.93%\n",
      "Epoch  33 | Loss: 0.18 | Acc: 92.11%\n",
      "Epoch  34 | Loss: 0.18 | Acc: 92.84%\n",
      "Epoch  35 | Loss: 0.18 | Acc: 94.02%\n",
      "Epoch  36 | Loss: 0.18 | Acc: 94.42%\n",
      "Epoch  37 | Loss: 0.17 | Acc: 94.49%\n",
      "Epoch  38 | Loss: 0.17 | Acc: 94.38%\n",
      "Epoch  39 | Loss: 0.17 | Acc: 94.36%\n",
      "Epoch  40 | Loss: 0.17 | Acc: 94.44%\n",
      "Epoch  41 | Loss: 0.17 | Acc: 94.78%\n",
      "Epoch  42 | Loss: 0.17 | Acc: 94.88%\n",
      "Epoch  43 | Loss: 0.17 | Acc: 94.86%\n",
      "Epoch  44 | Loss: 0.16 | Acc: 94.83%\n",
      "Epoch  45 | Loss: 0.16 | Acc: 94.82%\n",
      "Epoch  46 | Loss: 0.16 | Acc: 94.91%\n",
      "Epoch  47 | Loss: 0.16 | Acc: 94.98%\n",
      "Epoch  48 | Loss: 0.16 | Acc: 94.99%\n",
      "Epoch  49 | Loss: 0.16 | Acc: 94.93%\n",
      "Epoch  50 | Loss: 0.16 | Acc: 94.84%\n",
      "Epoch  51 | Loss: 0.15 | Acc: 94.91%\n",
      "Epoch  52 | Loss: 0.15 | Acc: 95.05%\n",
      "Epoch  53 | Loss: 0.15 | Acc: 95.14%\n",
      "Epoch  54 | Loss: 0.15 | Acc: 95.20%\n",
      "Epoch  55 | Loss: 0.15 | Acc: 95.32%\n",
      "Epoch  56 | Loss: 0.15 | Acc: 95.47%\n",
      "Epoch  57 | Loss: 0.15 | Acc: 95.60%\n",
      "Epoch  58 | Loss: 0.14 | Acc: 95.64%\n",
      "Epoch  59 | Loss: 0.14 | Acc: 95.62%\n",
      "Epoch  60 | Loss: 0.14 | Acc: 95.78%\n",
      "Epoch  61 | Loss: 0.14 | Acc: 95.95%\n",
      "Epoch  62 | Loss: 0.14 | Acc: 95.99%\n",
      "Epoch  63 | Loss: 0.14 | Acc: 95.94%\n",
      "Epoch  64 | Loss: 0.14 | Acc: 95.97%\n",
      "Epoch  65 | Loss: 0.14 | Acc: 96.00%\n",
      "Epoch  66 | Loss: 0.14 | Acc: 95.99%\n",
      "Epoch  67 | Loss: 0.14 | Acc: 95.98%\n",
      "Epoch  68 | Loss: 0.13 | Acc: 96.00%\n",
      "Epoch  69 | Loss: 0.13 | Acc: 95.98%\n",
      "Epoch  70 | Loss: 0.13 | Acc: 96.02%\n",
      "Epoch  71 | Loss: 0.13 | Acc: 96.07%\n",
      "Epoch  72 | Loss: 0.13 | Acc: 96.09%\n",
      "Epoch  73 | Loss: 0.13 | Acc: 96.08%\n",
      "Epoch  74 | Loss: 0.13 | Acc: 96.10%\n",
      "Epoch  75 | Loss: 0.13 | Acc: 96.09%\n",
      "Epoch  76 | Loss: 0.13 | Acc: 96.11%\n",
      "Epoch  77 | Loss: 0.13 | Acc: 96.10%\n",
      "Epoch  78 | Loss: 0.13 | Acc: 96.09%\n",
      "Epoch  79 | Loss: 0.13 | Acc: 96.09%\n",
      "Epoch  80 | Loss: 0.13 | Acc: 96.12%\n",
      "Epoch  81 | Loss: 0.13 | Acc: 96.11%\n",
      "Epoch  82 | Loss: 0.13 | Acc: 96.10%\n",
      "Epoch  83 | Loss: 0.13 | Acc: 96.10%\n",
      "Epoch  84 | Loss: 0.13 | Acc: 96.11%\n",
      "Epoch  85 | Loss: 0.12 | Acc: 96.12%\n",
      "Epoch  86 | Loss: 0.12 | Acc: 96.13%\n",
      "Epoch  87 | Loss: 0.12 | Acc: 96.13%\n",
      "Epoch  88 | Loss: 0.12 | Acc: 96.15%\n",
      "Epoch  89 | Loss: 0.12 | Acc: 96.16%\n",
      "Epoch  90 | Loss: 0.12 | Acc: 96.15%\n",
      "Epoch  91 | Loss: 0.12 | Acc: 96.16%\n",
      "Epoch  92 | Loss: 0.12 | Acc: 96.17%\n",
      "Epoch  93 | Loss: 0.12 | Acc: 96.19%\n",
      "Epoch  94 | Loss: 0.12 | Acc: 96.22%\n",
      "Epoch  95 | Loss: 0.12 | Acc: 96.22%\n",
      "Epoch  96 | Loss: 0.12 | Acc: 96.24%\n",
      "Epoch  97 | Loss: 0.12 | Acc: 96.25%\n",
      "Epoch  98 | Loss: 0.12 | Acc: 96.28%\n",
      "Epoch  99 | Loss: 0.12 | Acc: 96.28%\n",
      "Epoch 100 | Loss: 0.12 | Acc: 96.28%\n",
      "Epoch 101 | Loss: 0.12 | Acc: 96.30%\n",
      "Epoch 102 | Loss: 0.12 | Acc: 96.30%\n",
      "Epoch 103 | Loss: 0.12 | Acc: 96.31%\n",
      "Epoch 104 | Loss: 0.12 | Acc: 96.34%\n",
      "Epoch 105 | Loss: 0.12 | Acc: 96.34%\n",
      "Epoch 106 | Loss: 0.12 | Acc: 96.34%\n",
      "Epoch 107 | Loss: 0.12 | Acc: 96.35%\n",
      "Epoch 108 | Loss: 0.12 | Acc: 96.37%\n",
      "Epoch 109 | Loss: 0.12 | Acc: 96.35%\n",
      "Epoch 110 | Loss: 0.12 | Acc: 96.39%\n",
      "Epoch 111 | Loss: 0.12 | Acc: 96.36%\n",
      "Epoch 112 | Loss: 0.11 | Acc: 96.40%\n",
      "Epoch 113 | Loss: 0.11 | Acc: 96.34%\n",
      "Epoch 114 | Loss: 0.11 | Acc: 96.38%\n",
      "Epoch 115 | Loss: 0.11 | Acc: 96.42%\n",
      "Epoch 116 | Loss: 0.11 | Acc: 96.35%\n",
      "Epoch 117 | Loss: 0.11 | Acc: 96.44%\n",
      "Epoch 118 | Loss: 0.11 | Acc: 96.41%\n",
      "Epoch 119 | Loss: 0.11 | Acc: 96.46%\n",
      "Epoch 120 | Loss: 0.11 | Acc: 96.43%\n",
      "Epoch 121 | Loss: 0.11 | Acc: 96.42%\n",
      "Epoch 122 | Loss: 0.11 | Acc: 96.48%\n",
      "Epoch 123 | Loss: 0.11 | Acc: 96.42%\n",
      "Epoch 124 | Loss: 0.11 | Acc: 96.49%\n",
      "Epoch 125 | Loss: 0.11 | Acc: 96.46%\n",
      "Epoch 126 | Loss: 0.11 | Acc: 96.44%\n",
      "Epoch 127 | Loss: 0.11 | Acc: 96.55%\n",
      "Epoch 128 | Loss: 0.11 | Acc: 96.51%\n",
      "Epoch 129 | Loss: 0.11 | Acc: 96.53%\n",
      "Epoch 130 | Loss: 0.11 | Acc: 96.54%\n",
      "Epoch 131 | Loss: 0.11 | Acc: 96.49%\n",
      "Epoch 132 | Loss: 0.11 | Acc: 96.51%\n",
      "Epoch 133 | Loss: 0.11 | Acc: 96.55%\n",
      "Epoch 134 | Loss: 0.11 | Acc: 96.57%\n",
      "Epoch 135 | Loss: 0.11 | Acc: 96.59%\n",
      "Epoch 136 | Loss: 0.11 | Acc: 96.56%\n",
      "Epoch 137 | Loss: 0.11 | Acc: 96.56%\n",
      "Epoch 138 | Loss: 0.11 | Acc: 96.57%\n",
      "Epoch 139 | Loss: 0.11 | Acc: 96.56%\n",
      "Epoch 140 | Loss: 0.11 | Acc: 96.63%\n",
      "Epoch 141 | Loss: 0.11 | Acc: 96.61%\n",
      "Epoch 142 | Loss: 0.11 | Acc: 96.65%\n",
      "Epoch 143 | Loss: 0.11 | Acc: 96.63%\n",
      "Epoch 144 | Loss: 0.11 | Acc: 96.63%\n",
      "Epoch 145 | Loss: 0.10 | Acc: 96.65%\n",
      "Epoch 146 | Loss: 0.10 | Acc: 96.64%\n",
      "Epoch 147 | Loss: 0.10 | Acc: 96.67%\n",
      "Epoch 148 | Loss: 0.10 | Acc: 96.68%\n",
      "Epoch 149 | Loss: 0.10 | Acc: 96.68%\n",
      "Epoch 150 | Loss: 0.10 | Acc: 96.68%\n",
      "Epoch 151 | Loss: 0.10 | Acc: 96.69%\n",
      "Epoch 152 | Loss: 0.10 | Acc: 96.74%\n",
      "Epoch 153 | Loss: 0.10 | Acc: 96.70%\n",
      "Epoch 154 | Loss: 0.10 | Acc: 96.71%\n",
      "Epoch 155 | Loss: 0.11 | Acc: 96.60%\n",
      "Epoch 156 | Loss: 0.11 | Acc: 96.59%\n",
      "Epoch 157 | Loss: 0.10 | Acc: 96.68%\n",
      "Epoch 158 | Loss: 0.10 | Acc: 96.63%\n",
      "Epoch 159 | Loss: 0.11 | Acc: 96.57%\n",
      "Epoch 160 | Loss: 0.10 | Acc: 96.71%\n",
      "Epoch 161 | Loss: 0.11 | Acc: 96.52%\n",
      "Epoch 162 | Loss: 0.11 | Acc: 96.58%\n",
      "Epoch 163 | Loss: 0.10 | Acc: 96.69%\n",
      "Epoch 164 | Loss: 0.11 | Acc: 96.47%\n",
      "Epoch 165 | Loss: 0.10 | Acc: 96.75%\n",
      "Epoch 166 | Loss: 0.11 | Acc: 96.73%\n",
      "Epoch 167 | Loss: 0.10 | Acc: 96.69%\n",
      "Epoch 168 | Loss: 0.10 | Acc: 96.68%\n",
      "Epoch 169 | Loss: 0.10 | Acc: 96.65%\n",
      "Epoch 170 | Loss: 0.10 | Acc: 96.79%\n",
      "Epoch 171 | Loss: 0.10 | Acc: 96.60%\n",
      "Epoch 172 | Loss: 0.10 | Acc: 96.80%\n",
      "Epoch 173 | Loss: 0.10 | Acc: 96.66%\n",
      "Epoch 174 | Loss: 0.10 | Acc: 96.81%\n",
      "Epoch 175 | Loss: 0.10 | Acc: 96.76%\n",
      "Epoch 176 | Loss: 0.10 | Acc: 96.86%\n",
      "Epoch 177 | Loss: 0.10 | Acc: 96.86%\n",
      "Epoch 178 | Loss: 0.10 | Acc: 96.82%\n",
      "Epoch 179 | Loss: 0.10 | Acc: 96.84%\n",
      "Epoch 180 | Loss: 0.10 | Acc: 96.78%\n",
      "Epoch 181 | Loss: 0.10 | Acc: 96.83%\n",
      "Epoch 182 | Loss: 0.10 | Acc: 96.80%\n",
      "Epoch 183 | Loss: 0.10 | Acc: 96.88%\n",
      "Epoch 184 | Loss: 0.10 | Acc: 96.86%\n",
      "Epoch 185 | Loss: 0.10 | Acc: 96.86%\n",
      "Epoch 186 | Loss: 0.10 | Acc: 96.89%\n",
      "Epoch 187 | Loss: 0.10 | Acc: 96.84%\n",
      "Epoch 188 | Loss: 0.10 | Acc: 96.89%\n",
      "Epoch 189 | Loss: 0.10 | Acc: 96.87%\n",
      "Epoch 190 | Loss: 0.10 | Acc: 96.89%\n",
      "Epoch 191 | Loss: 0.10 | Acc: 96.90%\n",
      "Epoch 192 | Loss: 0.10 | Acc: 96.87%\n",
      "Epoch 193 | Loss: 0.10 | Acc: 96.93%\n",
      "Epoch 194 | Loss: 0.10 | Acc: 96.88%\n",
      "Epoch 195 | Loss: 0.09 | Acc: 96.92%\n",
      "Epoch 196 | Loss: 0.09 | Acc: 96.92%\n",
      "Epoch 197 | Loss: 0.09 | Acc: 96.91%\n",
      "Epoch 198 | Loss: 0.09 | Acc: 96.92%\n",
      "Epoch 199 | Loss: 0.09 | Acc: 96.94%\n",
      "Epoch 200 | Loss: 0.09 | Acc: 96.93%\n"
     ]
    }
   ],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(num_features, 128)  # GCNConv layer, 3 output channels\n",
    "        self.out = Linear(128, num_classes)    # Linear layer for classification output\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn(x, edge_index).relu()   # Apply GCN and ReLU\n",
    "        z = self.out(h)                      # Output layer\n",
    "        return h, z\n",
    "\n",
    "# Initialize the model\n",
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = len(label_mapping)  # Number of classes (2 in this case)\n",
    "model = GCN(num_features, num_classes)\n",
    "print(model)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "# Accuracy calculation function\n",
    "def accuracy(pred_y, y):\n",
    "    return (pred_y == y).sum() / len(y)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    h, z = model(data.x, data.edge_index)  # h: embeddings, z: logits\n",
    "    loss = criterion(z, data.y)            # Compute loss\n",
    "    loss.backward()                        # Backpropagate\n",
    "    optimizer.step()                       # Update model parameters\n",
    "    \n",
    "    if epoch % 1== 0:\n",
    "        acc = accuracy(z.argmax(dim=1), data.y)  # Calculate accuracy\n",
    "        print(f'Epoch {epoch:>3} | Loss: {loss:.2f} | Acc: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46564, 128])\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)\n",
    "# Estrazione degli embeddings dopo aver addestrato la GCN\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings, _ = model(data.x, data.edge_index)  # h: embeddings\n",
    "\n",
    "# Converti gli embeddings in un DataFrame Pandas\n",
    "embeddings_df = pd.DataFrame(embeddings.cpu().numpy())\n",
    "\n",
    "# Salva gli embeddings su un file CSV\n",
    "embeddings_df.to_csv('embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
