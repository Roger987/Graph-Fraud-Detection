{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import random\n",
    "from torch.nn import Linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 234355/234355 [00:01<00:00, 194178.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00, -1.7147e-01, -1.8467e-01,  ..., -9.7524e-02,\n",
      "         -1.2061e-01, -1.1979e-01],\n",
      "        [ 1.0000e+00, -1.7148e-01, -1.8467e-01,  ..., -9.7524e-02,\n",
      "         -1.2061e-01, -1.1979e-01],\n",
      "        [ 1.0000e+00, -1.7211e-01, -1.8467e-01,  ..., -1.8367e-01,\n",
      "         -1.2061e-01, -1.1979e-01],\n",
      "        ...,\n",
      "        [ 4.9000e+01, -1.7201e-01, -7.8182e-02,  ..., -9.7524e-02,\n",
      "         -1.2061e-01, -1.1979e-01],\n",
      "        [ 4.9000e+01, -1.7284e-01, -1.7662e-01,  ..., -1.4060e-01,\n",
      "          1.5197e+00,  1.5214e+00],\n",
      "        [ 4.9000e+01, -1.2037e-02, -1.3228e-01,  ..., -1.4060e-01,\n",
      "          1.5197e+00,  1.5214e+00]])\n",
      "Max edge index: 203768\n",
      "Number of nodes: 203769\n"
     ]
    }
   ],
   "source": [
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "\n",
    "# Preprocess the classes DataFrame\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))\n",
    "\n",
    "# Create a mapping for all nodes\n",
    "all_nodes_dict = {tx_id: i for i, tx_id in enumerate(classes['txId'])}\n",
    "\n",
    "# Create edges list with all nodes\n",
    "edges_list = [\n",
    "    (all_nodes_dict[edges['txId1'][i]], all_nodes_dict[edges['txId2'][i]])\n",
    "    for i in tqdm(range(len(edges)))\n",
    "    if edges['txId1'][i] in all_nodes_dict and edges['txId2'][i] in all_nodes_dict\n",
    "]\n",
    "edge_index = torch.tensor(edges_list, dtype=torch.long).T\n",
    "\n",
    "# Convert node features and labels    Parameter to (V) choose features used\n",
    "node_features = torch.tensor(df.iloc[:, 1:].values, dtype=torch.float)\n",
    "#edge_index = torch.tensor(filtered_edges_list.values.T, dtype=torch.int64)\n",
    "label_mapping = {'1': 0, '2': 1, 'unknown': -1} \n",
    "labels = torch.tensor(classes['label'].map(label_mapping).values, dtype=torch.long)\n",
    "\n",
    "# Create graph data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "print(node_features)\n",
    "edges = pd.read_csv(edges_path)\n",
    "\n",
    "# Check the maximum index in the edges\n",
    "print(f\"Max edge index: {edges.max().max()}\")\n",
    "print(f\"Number of nodes: {len(node_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gcn): GCNConv(166, 128)\n",
      "  (out): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "Epoch   0 | Loss: 2.01 | Acc: 14.45%\n",
      "Epoch  10 | Loss: 0.45 | Acc: 90.27%\n",
      "Epoch  20 | Loss: 0.26 | Acc: 90.43%\n",
      "Epoch  30 | Loss: 0.19 | Acc: 92.66%\n",
      "Epoch  40 | Loss: 0.16 | Acc: 94.02%\n",
      "Epoch  50 | Loss: 0.14 | Acc: 95.30%\n",
      "Epoch  60 | Loss: 0.12 | Acc: 95.83%\n",
      "Epoch  70 | Loss: 0.11 | Acc: 96.17%\n",
      "Epoch  80 | Loss: 0.10 | Acc: 96.45%\n",
      "Epoch  90 | Loss: 0.09 | Acc: 96.78%\n",
      "Epoch 100 | Loss: 0.09 | Acc: 96.99%\n",
      "Epoch 110 | Loss: 0.08 | Acc: 97.18%\n",
      "Epoch 120 | Loss: 0.08 | Acc: 97.28%\n",
      "Epoch 130 | Loss: 0.07 | Acc: 97.53%\n",
      "Epoch 140 | Loss: 0.07 | Acc: 97.61%\n",
      "Epoch 150 | Loss: 0.06 | Acc: 97.76%\n",
      "Epoch 160 | Loss: 0.06 | Acc: 97.90%\n",
      "Epoch 170 | Loss: 0.06 | Acc: 97.95%\n",
      "Epoch 180 | Loss: 0.06 | Acc: 98.09%\n",
      "Epoch 190 | Loss: 0.05 | Acc: 98.19%\n",
      "Epoch 200 | Loss: 0.05 | Acc: 98.29%\n"
     ]
    }
   ],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(num_features, 128)  # GCNConv layer, 3 output channels\n",
    "        self.out = Linear(128, num_classes)    # Linear layer for classification output\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn(x, edge_index).relu()   # Apply GCN and ReLU\n",
    "        z = self.out(h)                      # Output layer\n",
    "        return h, z\n",
    "\n",
    "# Initialize the model\n",
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = len(label_mapping)  # Number of classes (2 in this case)\n",
    "model = GCN(num_features, num_classes)\n",
    "print(model)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "# Accuracy calculation function\n",
    "def accuracy(pred_y, y):\n",
    "    return (pred_y == y).sum() / len(y)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    h, z = model(data.x, data.edge_index)  # h: embeddings, z: logits\n",
    "\n",
    "    # Exclude unlabeled nodes from the loss calculation\n",
    "    mask = data.y != -1  \n",
    "    loss = criterion(z[mask], data.y[mask]) # Compute loss\n",
    "    \n",
    "    loss.backward()                         # Backpropagate\n",
    "    optimizer.step()                        # Update model parameters\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = accuracy(z.argmax(dim=1)[mask], data.y[mask])  # Calculate accuracy\n",
    "        print(f'Epoch {epoch:>3} | Loss: {loss:.2f} | Acc: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([203769, 128])\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)\n",
    "# Estrazione degli embeddings dopo aver addestrato la GCN\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings, _ = model(data.x, data.edge_index)  # h: embeddings\n",
    "\n",
    "# Converti gli embeddings in un DataFrame Pandas\n",
    "embeddings_df = pd.DataFrame(embeddings.cpu().numpy())\n",
    "\n",
    "# Salva gli embeddings su un file CSV\n",
    "embeddings_df.to_csv('embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
