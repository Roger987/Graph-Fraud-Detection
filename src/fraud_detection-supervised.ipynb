{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The graph is made of 203,769 nodes and 234,355 edges. Two percent (4,545) of the nodes are \n",
    "# labelled class1 (illicit).\n",
    "#Twenty-one percent (42,019) are labelled class2 (licit). \n",
    "#The remaining transactions are not labelled with regard to licit versus illicit.\n",
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_colors = {'1':'red', '2':'green', 'unknown':'gray'}\n",
    "\n",
    "tx_graph = ig.Graph(directed=True)\n",
    "\n",
    "edges_dict = {tx_id: i for i, tx_id in enumerate(classes['txId'])}\n",
    "\n",
    "tx_graph.add_vertices(len(classes))\n",
    "tx_graph.vs['id'] = list(classes['txId'])\n",
    "tx_graph.vs['type'] = list(classes['label'])\n",
    "tx_graph.vs['time_step'] = list(feats['time_step'])\n",
    "tx_graph.vs['color'] = [label_colors[label] for label in classes['label']]\n",
    "\n",
    "edges_list = [(edges_dict[edges['txId1'][i]], edges_dict[edges['txId2'][i]]) for i in tqdm(range(len(edges)))]\n",
    "tx_graph.add_edges(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = tx_graph.betweenness(directed=True)\n",
    "#df.insert(1, 'betweenness', betweenness, True)\n",
    "\n",
    "centralities = tx_graph.closeness()\n",
    "df.insert(1, 'closeness', centralities, True)\n",
    "\n",
    "in_degree = tx_graph.degree(mode=\"in\")\n",
    "df.insert(1, 'in-degree', in_degree)\n",
    "\n",
    "out_degree = tx_graph.degree(mode='out')\n",
    "df.insert(1, 'out-degree', out_degree)\n",
    "\n",
    "clustering_coeff = tx_graph.transitivity_local_undirected(mode='zero')\n",
    "df.insert(1, 'clustering_coeff', clustering_coeff)\n",
    "\n",
    "pagerank_scores = tx_graph.pagerank(directed=True)\n",
    "df.insert(1, 'pagerank', pagerank_scores, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Shortest paths with one random sample for every node.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "shortest_paths = [float(line.strip()) for line in lines]\n",
    "df.insert(1, 'avg_shortest_paths', shortest_paths, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, make_scorer, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the dataframe in a suitable input for KMeans. We drop the columns containing\n",
    "#the correct labels\n",
    "df.drop(df[df[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "\n",
    "y = df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "#X = X.loc[:, 'time_step':'trans_feat_92']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['time_step'].between(1, 34)]\n",
    "y_train = y[X['time_step'].between(1, 34)]\n",
    "\n",
    "X_test = X[X['time_step'].between(35, 49)]\n",
    "y_test = y[X['time_step'].between(35, 49)]\n",
    "\n",
    "#X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "#X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "#X_train = X_train.reset_index(drop=True)\n",
    "#y_train = y_train.reset_index(drop=True)\n",
    "#X_test = X_test.reset_index(drop=True)\n",
    "#y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LF = X_train.loc[:, 'time_step':'trans_feat_92']\n",
    "X_test_LF = X_test.loc[:, 'time_step':'trans_feat_92']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_LF.fit(X_train_LF, y_train)\n",
    "y_pred_LF = clf_LF.predict(X_test_LF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_ilicit_lf = precision_score(y_test, y_pred_LF, pos_label='1')\n",
    "recall_ilicit_lf = recall_score(y_test, y_pred_LF, pos_label='1')\n",
    "f1_ilicit_lf = f1_score(y_test, y_pred_LF, pos_label='1')\n",
    "f1_scorer_lf = make_scorer(f1_score, pos_label='1')\n",
    "scores_lf = cross_val_score(clf_LF, X_train_LF, y_train, cv=5, scoring=f1_scorer_lf)\n",
    "\n",
    "print(f'Precision local features: {precision_ilicit_lf}')\n",
    "print(f'Recall local features: {recall_ilicit_lf}')\n",
    "print(f'F1 local features: {f1_ilicit_lf}')\n",
    "print(\"Cross-validated F1 Score local features:\", scores_lf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_AF = X_train.loc[:, 'time_step':]\n",
    "X_test_AF = X_test.loc[:, 'time_step':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_AF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_AF.fit(X_train_AF, y_train)\n",
    "y_pred_AF = clf_AF.predict(X_test_AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_ilicit_af = precision_score(y_test, y_pred_AF, pos_label='1')\n",
    "recall_ilicit_af = recall_score(y_test, y_pred_AF, pos_label='1')\n",
    "f1_ilicit_af = f1_score(y_test, y_pred_AF, pos_label='1')\n",
    "f1_scorer_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_af = cross_val_score(clf_AF, X_train_AF, y_train, cv=5, scoring=f1_scorer_af)\n",
    "\n",
    "print(f'Precision all features: {precision_ilicit_af}')\n",
    "print(f'Recall all features: {recall_ilicit_af}')\n",
    "print(f'F1 all features: {f1_ilicit_af}')\n",
    "print(\"Cross-validated F1 Score all features:\", scores_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Features + Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LF_NF = X_train.loc[:, :'trans_feat_92']\n",
    "X_test_LF_NF = X_test.loc[:, :'trans_feat_92']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LF_NF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_LF_NF.fit(X_train_LF_NF, y_train)\n",
    "y_pred_LF_NF = clf_LF_NF.predict(X_test_LF_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_ilicit_lf_nf = precision_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "recall_ilicit_lf_nf = recall_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "f1_ilicit_lf_nf = f1_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "f1_scorer_lf_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_lf_nf = cross_val_score(clf_LF_NF, X_train_LF_NF, y_train, cv=5, scoring=f1_scorer_lf_nf)\n",
    "\n",
    "print(f'Precision local features + node features: {precision_ilicit_lf_nf}')\n",
    "print(f'Recall local features + node features: {recall_ilicit_lf_nf}')\n",
    "print(f'F1 local features + node features: {f1_ilicit_lf_nf}')\n",
    "print(\"Cross-validated F1 Score local features + node featuress:\", scores_lf_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features + Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_AF_NF = X_train.loc[:, :]\n",
    "X_test_AF_NF = X_test.loc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_AF_NF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_AF_NF.fit(X_train_AF_NF, y_train)\n",
    "y_pred_AF_NF = clf_AF_NF.predict(X_test_AF_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_ilicit_af_nf = precision_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "recall_ilicit_af_nf = recall_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "f1_ilicit_af_nf = f1_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "f1_scorer_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_af_nf = cross_val_score(clf_AF_NF, X_train_AF_NF, y_train, cv=5, scoring=f1_scorer_af_nf)\n",
    "\n",
    "print(f'Precision all features + node features: {precision_ilicit_af_nf}')\n",
    "print(f'Recall all features + node features: {recall_ilicit_af_nf}')\n",
    "print(f'F1 all features + node features: {f1_ilicit_af_nf}')\n",
    "print(\"Cross-validated F1 Score all features + node featuress:\", scores_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Embeddings (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv('../data/embeddings_gcn.csv')\n",
    "embeddings.drop(embeddings[embeddings[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings\n",
    "\n",
    "y_gcn = embeddings['label']\n",
    "X_gcn = embeddings.drop(columns=['label'])\n",
    "\n",
    "X_train_gcn = X_gcn[X_gcn['time_step'].between(1, 34)]\n",
    "y_train_gcn = y_gcn[X_gcn['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gcn = X_gcn[X_gcn['time_step'].between(35, 49)]\n",
    "y_test_gcn = y_gcn[X_gcn['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gcn = X_train_gcn.loc[:, '0':'127']\n",
    "X_test_gcn = X_test_gcn.loc[:, '0':'127']\n",
    "\n",
    "clf_gcn = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gcn.fit(X_train_gcn, y_train_gcn)\n",
    "y_pred_gcn = clf_gcn.predict(X_test_gcn)\n",
    "\n",
    "precision_ilicit_gcn = precision_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "recall_ilicit_gcn = recall_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "f1_ilicit_gcn = f1_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "f1_scorer_gcn = make_scorer(f1_score, pos_label='1')\n",
    "scores_gcn = cross_val_score(clf_gcn, X_train_gcn, y_train_gcn, cv=5, scoring=f1_scorer_gcn)\n",
    "\n",
    "print(f'Precision node embeddings (GCN): {precision_ilicit_gcn}')\n",
    "print(f'Recall node embeddings (GCN): {recall_ilicit_gcn}')\n",
    "print(f'F1 node embeddings (GCN): {f1_ilicit_gcn}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GCN):\", scores_gcn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings + All Features (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ne_af = df.loc[:, 'time_step':].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_af = df_ne_af.drop(columns=['label'])\n",
    "y_ne_af = df_ne_af['label']\n",
    "\n",
    "X_train_ne_af = X_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "y_train_ne_af = y_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af = X_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "y_test_ne_af = y_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af.fit(X_train_ne_af, y_train_ne_af)\n",
    "y_pred_ne_af = clf_ne_af.predict(X_test_ne_af)\n",
    "\n",
    "precision_ilicit_ne_af = precision_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "recall_ilicit_ne_af = recall_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_ilicit_ne_af = f1_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_scorer_ne_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af = cross_val_score(clf_ne_af, X_train_ne_af, y_train_ne_af, cv=5, scoring=f1_scorer_ne_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_ne_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_ne_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_ne_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings + All Features + Node Features (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ne_af_nf = df.loc[:,:].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "df_ne_af_nf = df.loc[:,:].join(embeddings.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_ne_af_nf = df_ne_af_nf.drop(columns=['label'])\n",
    "y_ne_af_nf = df_ne_af_nf['label']\n",
    "\n",
    "X_train_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "y_train_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "y_test_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af_nf.fit(X_train_ne_af_nf, y_train_ne_af_nf)\n",
    "y_pred_ne_af_nf = clf_ne_af_nf.predict(X_test_ne_af_nf)\n",
    "\n",
    "precision_ilicit_ne_af_nf = precision_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "recall_ilicit_ne_af_nf = recall_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_ilicit_ne_af_nf = f1_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_scorer_ne_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af_nf = cross_val_score(clf_ne_af_nf, X_train_ne_af_nf, y_train_ne_af_nf, cv=5, scoring=f1_scorer_ne_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_ne_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_ne_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_ne_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Emebddings (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_gat = pd.read_csv('../data/embeddings_gat.csv')\n",
    "\n",
    "embeddings_gat.drop(embeddings_gat[embeddings_gat[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings_gat\n",
    "\n",
    "y_gat = embeddings_gat['label']\n",
    "X_gat = embeddings_gat.drop(columns=['label'])\n",
    "\n",
    "X_train_gat = X_gat[X_gat['time_step'].between(1, 34)]\n",
    "y_train_gat = y_gat[X_gat['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gat = X_gat[X_gat['time_step'].between(35, 49)]\n",
    "y_test_gat = y_gat[X_gat['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gat = X_train_gat.loc[:, '0':'127']\n",
    "X_test_gat = X_test_gat.loc[:, '0':'127']\n",
    "\n",
    "clf_gat = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gat.fit(X_train_gat, y_train_gat)\n",
    "y_pred_gat = clf_gat.predict(X_test_gat)\n",
    "\n",
    "precision_ilicit_gat = precision_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "recall_ilicit_gat = recall_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "f1_ilicit_gat = f1_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "f1_scorer_gat = make_scorer(f1_score, pos_label='1')\n",
    "scores_gat = cross_val_score(clf_gat, X_train_gat, y_train_gat, cv=5, scoring=f1_scorer_gat)\n",
    "\n",
    "print(f'Precision node embeddings (GAT): {precision_ilicit_gat}')\n",
    "print(f'Recall node embeddings (GAT): {recall_ilicit_gat}')\n",
    "print(f'F1 node embeddings (GAT): {f1_ilicit_gat}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GAT):\", scores_gat.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ne_af = df.loc[:, 'time_step':].join(embeddings_gat.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_af = df_ne_af.drop(columns=['label'])\n",
    "y_ne_af = df_ne_af['label']\n",
    "\n",
    "X_train_ne_af = X_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "y_train_ne_af = y_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af = X_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "y_test_ne_af = y_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af.fit(X_train_ne_af, y_train_ne_af)\n",
    "y_pred_ne_af = clf_ne_af.predict(X_test_ne_af)\n",
    "\n",
    "precision_ilicit_ne_af = precision_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "recall_ilicit_ne_af = recall_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_ilicit_ne_af = f1_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_scorer_ne_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af = cross_val_score(clf_ne_af, X_train_ne_af, y_train_ne_af, cv=5, scoring=f1_scorer_ne_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_ne_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_ne_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_ne_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features + Node Features (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ne_af_nf = df.loc[:,:].join(embeddings_gat.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_ne_af_nf = df_ne_af_nf.drop(columns=['label'])\n",
    "y_ne_af_nf = df_ne_af_nf['label']\n",
    "\n",
    "X_train_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "y_train_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "y_test_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af_nf.fit(X_train_ne_af_nf, y_train_ne_af_nf)\n",
    "y_pred_ne_af_nf = clf_ne_af_nf.predict(X_test_ne_af_nf)\n",
    "\n",
    "precision_ilicit_ne_af_nf = precision_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "recall_ilicit_ne_af_nf = recall_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_ilicit_ne_af_nf = f1_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_scorer_ne_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af_nf = cross_val_score(clf_ne_af_nf, X_train_ne_af_nf, y_train_ne_af_nf, cv=5, scoring=f1_scorer_ne_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_ne_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_ne_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_ne_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Emebddings (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_gin = pd.read_csv('../data/embeddings_gin.csv')\n",
    "\n",
    "embeddings_gin.drop(embeddings_gin[embeddings_gin[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings_gin\n",
    "\n",
    "y_gin = embeddings_gin['label']\n",
    "X_gin = embeddings_gin.drop(columns=['label'])\n",
    "\n",
    "X_train_gin = X_gin[X_gin['time_step'].between(1, 34)]\n",
    "y_train_gin = y_gin[X_gin['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gin = X_gin[X_gin['time_step'].between(35, 49)]\n",
    "y_test_gin = y_gin[X_gin['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gin = X_train_gin.loc[:, '0':'127']\n",
    "X_test_gin = X_test_gin.loc[:, '0':'127']\n",
    "\n",
    "clf_gin = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gin.fit(X_train_gin, y_train_gin)\n",
    "y_pred_gin = clf_gin.predict(X_test_gin)\n",
    "\n",
    "precision_ilicit_gin = precision_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "recall_ilicit_gin = recall_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "f1_ilicit_gin = f1_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "f1_scorer_gin = make_scorer(f1_score, pos_label='1')\n",
    "scores_gin = cross_val_score(clf_gin, X_train_gin, y_train_gin, cv=5, scoring=f1_scorer_gin)\n",
    "\n",
    "print(f'Precision node embeddings (GIN): {precision_ilicit_gin}')\n",
    "print(f'Recall node embeddings (GIN): {recall_ilicit_gin}')\n",
    "print(f'F1 node embeddings (GIN): {f1_ilicit_gin}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GIN):\", scores_gin.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Node Embeddings + All Features (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ne_af = df.loc[:, 'time_step':].join(embeddings_gin.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_af = df_ne_af.drop(columns=['label'])\n",
    "y_ne_af = df_ne_af['label']\n",
    "\n",
    "X_train_ne_af = X_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "y_train_ne_af = y_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af = X_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "y_test_ne_af = y_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af.fit(X_train_ne_af, y_train_ne_af)\n",
    "y_pred_ne_af = clf_ne_af.predict(X_test_ne_af)\n",
    "\n",
    "precision_ilicit_ne_af = precision_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "recall_ilicit_ne_af = recall_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_ilicit_ne_af = f1_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_scorer_ne_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af = cross_val_score(clf_ne_af, X_train_ne_af, y_train_ne_af, cv=5, scoring=f1_scorer_ne_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_ne_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_ne_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_ne_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features + Node Features (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ne_af_nf = df.loc[:,:].join(embeddings_gin.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_ne_af_nf = df_ne_af_nf.drop(columns=['label'])\n",
    "y_ne_af_nf = df_ne_af_nf['label']\n",
    "\n",
    "X_train_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "y_train_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "y_test_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af_nf.fit(X_train_ne_af_nf, y_train_ne_af_nf)\n",
    "y_pred_ne_af_nf = clf_ne_af_nf.predict(X_test_ne_af_nf)\n",
    "\n",
    "precision_ilicit_ne_af_nf = precision_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "recall_ilicit_ne_af_nf = recall_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_ilicit_ne_af_nf = f1_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_scorer_ne_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af_nf = cross_val_score(clf_ne_af_nf, X_train_ne_af_nf, y_train_ne_af_nf, cv=5, scoring=f1_scorer_ne_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_ne_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_ne_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_ne_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = (y_test == '1').astype(int)\n",
    "\n",
    "class_index_lf = clf_LF.classes_.tolist().index('1')  \n",
    "y_prob_lf = clf_LF.predict_proba(X_test_LF)[:, class_index_lf]\n",
    "\n",
    "class_index_af = clf_AF.classes_.tolist().index('1')  \n",
    "y_prob_af = clf_AF.predict_proba(X_test_AF)[:, class_index_af]\n",
    "\n",
    "class_index_lf_nf = clf_LF_NF.classes_.tolist().index('1')  \n",
    "y_prob_lf_nf = clf_LF_NF.predict_proba(X_test_LF_NF)[:, class_index_lf_nf]\n",
    "\n",
    "class_index_af_nf = clf_AF_NF.classes_.tolist().index('1')  \n",
    "y_prob_af_nf = clf_AF_NF.predict_proba(X_test_AF_NF)[:, class_index_af_nf]\n",
    "\n",
    "class_index_ne_af = clf_ne_af.classes_.tolist().index('1')  \n",
    "y_prob_ne_af = clf_ne_af.predict_proba(X_test_ne_af)[:, class_index_ne_af]\n",
    "\n",
    "class_index_ne_af_nf = clf_ne_af_nf.classes_.tolist().index('1')  \n",
    "y_prob_ne_af_nf = clf_ne_af_nf.predict_proba(X_test_ne_af_nf)[:, class_index_ne_af_nf]\n",
    "\n",
    "fpr_lf, tpr_lf, thresholds_lf = roc_curve(y_test, y_prob_lf, pos_label='1')\n",
    "fpr_af, tpr_af, thresholds_af = roc_curve(y_test, y_prob_af, pos_label='1')\n",
    "fpr_lf_nf, tpr_lf_nf, thresholds_lf_nf = roc_curve(y_test, y_prob_lf_nf, pos_label='1')\n",
    "fpr_af_nf, tpr_af_nf, thresholds_af_nf = roc_curve(y_test, y_prob_af_nf, pos_label='1')\n",
    "fpr_ne_af, tpr_ne_af, thresholds_ne_af = roc_curve(y_test, y_prob_ne_af, pos_label='1')\n",
    "fpr_ne_af_nf, tpr_ne_af_nf, thresholds_ne_af_nf = roc_curve(y_test, y_prob_ne_af_nf, pos_label='1')\n",
    "\n",
    "roc_auc_lf = roc_auc_score(y_test_binary, y_prob_lf)\n",
    "print(f\"ROC-AUC Score for illicit (Local Features): {roc_auc_lf:.3f}\")\n",
    "\n",
    "roc_auc_af = roc_auc_score(y_test_binary, y_prob_af)\n",
    "print(f\"ROC-AUC Score for illicit (All Features): {roc_auc_af:.3f}\")\n",
    "\n",
    "roc_auc_lf_nf = roc_auc_score(y_test_binary, y_prob_lf_nf)\n",
    "print(f\"ROC-AUC Score for illicit (Local Features + Node Features): {roc_auc_lf_nf:.3f}\")\n",
    "\n",
    "roc_auc_af_nf = roc_auc_score(y_test_binary, y_prob_af_nf)\n",
    "print(f\"ROC-AUC Score for illicit (All Features + Node Features): {roc_auc_af_nf:.3f}\")\n",
    "\n",
    "roc_auc_ne_af = roc_auc_score(y_test_binary, y_prob_ne_af)\n",
    "print(f\"ROC-AUC Score for illicit (Node Embeddings + All features (GCN)): {roc_auc_ne_af:.3f}\")\n",
    "\n",
    "roc_auc_ne_af_nf = roc_auc_score(y_test_binary, y_prob_ne_af_nf)\n",
    "print(f\"ROC-AUC Score for illicit (Embeddings + All Features + Node Features (GCN)): {roc_auc_ne_af_nf:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lf, tpr_lf, label=f\"ROC Curve (AUC = {roc_auc_lf:.3f}) for illicit lf\")\n",
    "plt.plot(fpr_af, tpr_af, label=f\"ROC Curve (AUC = {roc_auc_af:.3f}) for illicit af\")\n",
    "plt.plot(fpr_lf_nf, tpr_lf_nf, label=f\"ROC Curve (AUC = {roc_auc_lf_nf:.3f}) for illicit nf+lf\")\n",
    "plt.plot(fpr_af_nf, tpr_af_nf, label=f\"ROC Curve (AUC = {roc_auc_af_nf:.3f}) for illicit af+nf\")\n",
    "plt.plot(fpr_ne_af, tpr_ne_af, label=f\"ROC Curve (AUC = {roc_auc_ne_af:.3f}) for illicit ne+af (GCN)\")\n",
    "plt.plot(fpr_ne_af_nf, tpr_ne_af_nf, label=f\"ROC Curve (AUC = {roc_auc_ne_af_nf:.3f}) for illicit embeddings+af+nf (GCN)\")\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', alpha=0.6, label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for illicit\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#importances = clf.feature_importances_\n",
    "#features = X.columns  \n",
    "\n",
    "#feature_importances = pd.DataFrame({\n",
    "#    'Feature': features,\n",
    "#    'Importance': importances\n",
    "#})\n",
    "\n",
    "#feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "#top_features = feature_importances.head(50)\n",
    "\n",
    "#print(top_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#fig, ax = plt.subplots(figsize=(20, 20)) \n",
    "#node_sizes = [c * 50 for c in centralities]\n",
    "#layout = tx_graph.layout_fruchterman_reingold()\n",
    "#ig.plot(tx_graph, vertex_size=node_sizes, vertex_frame_width=0.5, edge_width=0.1, bbox=(8000, 8000), margin=50, target=ax)\n",
    "#plt.savefig(\"large_graph.png\", dpi=300)\n",
    "#plt.savefig(\"large_graph.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#undirected_graph = tx_graph.as_undirected(combine_edges=None)\n",
    "#ilicit_indices = [v.index for v in undirected_graph.vs if v['type'] == '1']\n",
    "#ilicit_graph = undirected_graph.induced_subgraph(ilicit_indices)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(20, 20)) \n",
    "#ilicit_centralities = ilicit_graph.closeness()\n",
    "#node_sizes = [c * 50 for c in centralities]\n",
    "#layout = ilicit_graph.layout_fruchterman_reingold()\n",
    "#ig.plot(ilicit_graph, vertex_size=node_sizes, vertex_frame_width=0.5, edge_width=0.1, bbox=(8000, 8000), margin=50, target=ax)\n",
    "#plt.savefig(\"ilicit_graph.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = X['time_step']\n",
    "\n",
    "grouped_data = df.groupby(['time_step', 'label']).size().unstack(fill_value=0)\n",
    "grouped_data.plot(kind='bar', figsize=(12, 6), width=0.8, edgecolor='black')\n",
    "\n",
    "plt.title('Licit and ilicit operations through time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('# of operations')\n",
    "plt.xticks(range(4, 50, 5), rotation=0)\n",
    "plt.legend(title='Label', labels=['ilicit', 'licit'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "illicit_data = df[df['label'] == '1']\n",
    "\n",
    "grouped_illicit = illicit_data.groupby('time_step').size()\n",
    "\n",
    "grouped_illicit.plot(kind='bar', figsize=(12, 6), width=0.8, edgecolor='lightblue', color='lightblue')\n",
    "\n",
    "plt.title('Illicit Operations Through Time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('# of Illicit Operations')\n",
    "plt.xticks(range(4, 50, 5), rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_by_time_lf = []\n",
    "precision_by_time_af = []\n",
    "precision_by_time_lf_nf = []\n",
    "precision_by_time_af_nf = []\n",
    "precision_by_time_ne_af_nf = []\n",
    "\n",
    "time_steps = sorted(df[df['time_step'] >= 35]['time_step'].unique())\n",
    "\n",
    "for step in time_steps:\n",
    "    y_true = y_test[X_test['time_step'] == step]  \n",
    "    \n",
    "    y_pred_step_lf = y_pred_LF[X_test['time_step'] == step]\n",
    "    y_pred_step_af = y_pred_AF[X_test['time_step'] == step]\n",
    "    y_pred_step_lf_nf = y_pred_LF_NF[X_test['time_step'] == step]\n",
    "    y_pred_step_af_nf = y_pred_AF_NF[X_test['time_step'] == step]\n",
    "    y_pred_step_ne_af_nf = y_pred_ne_af_nf[X_test['time_step'] == step]\n",
    "    \n",
    "\n",
    "    if len(y_true) > 0:  \n",
    "        precision_lf = precision_score(y_true, y_pred_step_lf, pos_label='1', zero_division=0)\n",
    "        precision_af = precision_score(y_true, y_pred_step_af, pos_label='1', zero_division=0)\n",
    "        precision_lf_nf = precision_score(y_true, y_pred_step_lf_nf, pos_label='1', zero_division=0)\n",
    "        precision_af_nf = precision_score(y_true, y_pred_step_af_nf, pos_label='1', zero_division=0)\n",
    "        precision_ne_af_nf = precision_score(y_true, y_pred_step_ne_af_nf, pos_label='1', zero_division=0)\n",
    "        \n",
    "        precision_by_time_lf.append(precision_lf)\n",
    "        precision_by_time_af.append(precision_af)\n",
    "        precision_by_time_lf_nf.append(precision_lf_nf)\n",
    "        precision_by_time_af_nf.append(precision_af_nf)\n",
    "        precision_by_time_ne_af_nf.append(precision_ne_af_nf)\n",
    "    else:\n",
    "        precision_by_time_lf.append(0)  \n",
    "        precision_by_time_af.append(0)\n",
    "        precision_by_time_lf_nf.append(0)\n",
    "        precision_by_time_af_nf.append(0)\n",
    "        precision_by_time_ne_af_nf.append(0)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "illicit_data = df[(df['label'] == '1') & (df['time_step'] >= 35)]\n",
    "\n",
    "grouped_illicit = illicit_data.groupby('time_step').size()\n",
    "\n",
    "plt.title('Illicit Operations Through Time')\n",
    "\n",
    "ax1.set_xlabel('Time Step')\n",
    "ax1.set_ylabel('# of Illicit Operations')\n",
    "ax1.set_xticks(range(len(grouped_illicit)), grouped_illicit.index, rotation=0)\n",
    "ax1.bar(time_steps, grouped_illicit, width=0.8, edgecolor='lightblue', color='lightblue')\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel('F-1 Score')\n",
    "line_lf, = ax2.plot(time_steps, precision_by_time_lf, color='red', marker='o')\n",
    "line_af, = ax2.plot(time_steps, precision_by_time_af, color='orange', marker='x', label='All Features')\n",
    "line_lf_nf, = ax2.plot(time_steps, precision_by_time_lf_nf, color='magenta', marker='^', label='Local Featuras + Node Features')\n",
    "line_af_nf, = ax2.plot(time_steps, precision_by_time_af_nf, color='cyan', marker='v', label='All Featuras + Node Features')\n",
    "line_ne_af_nf, = ax2.plot(time_steps, precision_by_time_ne_af_nf, color='yellow', marker='D', label='Node Embeddings + All Featuras + Node Features')\n",
    "\n",
    "ax2.legend([line_lf, line_af, line_lf_nf, line_af_nf, line_ne_af_nf], ['Local Features', 'All Features', 'Local Featuras + Node Features', 'All Featuras + Node Features', 'Node Embeddings + All Featuras + Node Features'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
