{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The graph is made of 203,769 nodes and 234,355 edges. Two percent (4,545) of the nodes are \n",
    "# labelled class1 (illicit).\n",
    "#Twenty-one percent (42,019) are labelled class2 (licit). \n",
    "#The remaining transactions are not labelled with regard to licit versus illicit.\n",
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 234355/234355 [00:00<00:00, 491697.60it/s]\n"
     ]
    }
   ],
   "source": [
    "label_colors = {'1':'red', '2':'green', 'unknown':'gray'}\n",
    "\n",
    "tx_graph = ig.Graph(directed=True)\n",
    "\n",
    "edges_dict = {tx_id: i for i, tx_id in enumerate(classes['txId'])}\n",
    "\n",
    "tx_graph.add_vertices(len(classes))\n",
    "tx_graph.vs['id'] = list(classes['txId'])\n",
    "tx_graph.vs['type'] = list(classes['label'])\n",
    "tx_graph.vs['time_step'] = list(feats['time_step'])\n",
    "tx_graph.vs['color'] = [label_colors[label] for label in classes['label']]\n",
    "\n",
    "edges_list = [(edges_dict[edges['txId1'][i]], edges_dict[edges['txId2'][i]]) for i in tqdm(range(len(edges)))]\n",
    "tx_graph.add_edges(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = tx_graph.betweenness(directed=True)\n",
    "df.insert(1, 'betweenness', betweenness, True)\n",
    "\n",
    "centralities = tx_graph.closeness()\n",
    "df.insert(1, 'closeness', centralities, True)\n",
    "\n",
    "in_degree = tx_graph.degree(mode=\"in\")\n",
    "df.insert(1, 'in-degree', in_degree)\n",
    "\n",
    "out_degree = tx_graph.degree(mode='out')\n",
    "df.insert(1, 'out-degree', out_degree)\n",
    "\n",
    "clustering_coeff = tx_graph.transitivity_local_undirected(mode='zero')\n",
    "df.insert(1, 'clustering_coeff', clustering_coeff)\n",
    "\n",
    "pagerank_scores = tx_graph.pagerank(directed=True)\n",
    "df.insert(1, 'pagerank', pagerank_scores, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Shortest paths with one random sample for every node.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "shortest_paths = [float(line.strip()) for line in lines]\n",
    "df.insert(1, 'avg_shortest_paths', shortest_paths, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>avg_shortest_paths</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>clustering_coeff</th>\n",
       "      <th>out-degree</th>\n",
       "      <th>in-degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>time_step</th>\n",
       "      <th>trans_feat_0</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_62</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>10.560976</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562153</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>unknown</td>\n",
       "      <td>11.486842</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084580</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>7.410526</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134507</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670883</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0.155365</td>\n",
       "      <td>2355.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>9.661290</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100978</td>\n",
       "      <td>16.752381</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  avg_shortest_paths  pagerank  clustering_coeff  out-degree  \\\n",
       "txId                                                                        \n",
       "0     unknown           10.560976  0.000004          0.000000           1   \n",
       "5577  unknown           11.486842  0.000005          0.000000           1   \n",
       "1     unknown            7.410526  0.000005          0.000000           2   \n",
       "537         2            6.857143  0.000297          0.000621           1   \n",
       "2     unknown            9.661290  0.000002          0.266667           8   \n",
       "\n",
       "      in-degree  closeness  betweenness  time_step  trans_feat_0  ...  \\\n",
       "txId                                                              ...   \n",
       "0             1   0.092392    14.000000          1     -0.171469  ...   \n",
       "5577          1   0.084580     8.000000          1     -0.171484  ...   \n",
       "1             1   0.134507    30.000000          1     -0.172107  ...   \n",
       "537         160   0.155365  2355.000000          1      0.163054  ...   \n",
       "2             2   0.100978    16.752381          1      1.011523  ...   \n",
       "\n",
       "      agg_feat_62  agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  \\\n",
       "txId                                                                    \n",
       "0       -0.562153    -0.600999     1.461330     1.461369     0.018279   \n",
       "5577     0.947382     0.673103    -0.979074    -0.978556     0.018279   \n",
       "1        0.670883     0.439728    -0.979074    -0.978556    -0.098889   \n",
       "537     -0.577099    -0.613614     0.241128     0.241406     1.072793   \n",
       "2       -0.511871    -0.400422     0.517257     0.579382     0.018279   \n",
       "\n",
       "      agg_feat_67  agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  \n",
       "txId                                                                   \n",
       "0       -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "5577    -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "1       -0.106715    -0.131155    -0.183671    -0.120613    -0.119792  \n",
       "537      0.085530    -0.131155     0.677799    -0.120613    -0.119792  \n",
       "2        0.277775     0.326394     1.293750     0.178136     0.179117  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203769, 174)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, make_scorer, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_shortest_paths</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>clustering_coeff</th>\n",
       "      <th>out-degree</th>\n",
       "      <th>in-degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>time_step</th>\n",
       "      <th>trans_feat_0</th>\n",
       "      <th>trans_feat_1</th>\n",
       "      <th>...</th>\n",
       "      <th>agg_feat_62</th>\n",
       "      <th>agg_feat_63</th>\n",
       "      <th>agg_feat_64</th>\n",
       "      <th>agg_feat_65</th>\n",
       "      <th>agg_feat_66</th>\n",
       "      <th>agg_feat_67</th>\n",
       "      <th>agg_feat_68</th>\n",
       "      <th>agg_feat_69</th>\n",
       "      <th>agg_feat_70</th>\n",
       "      <th>agg_feat_71</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0.155365</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>6.771084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.134193</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005027</td>\n",
       "      <td>0.578941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.604120</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.333211</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.216216</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147852</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>8.028169</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110372</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539735</td>\n",
       "      <td>-0.582077</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.848485</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139805</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172306</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.054450</td>\n",
       "      <td>-1.760926</td>\n",
       "      <td>-1.760984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_shortest_paths  pagerank  clustering_coeff  out-degree  in-degree  \\\n",
       "txId                                                                          \n",
       "537             6.857143  0.000297          0.000621           1        160   \n",
       "4133            6.771084  0.000076          0.001130           1         59   \n",
       "5              10.216216  0.000002          0.000000           2          0   \n",
       "5187            8.028169  0.000002          0.000000           1          1   \n",
       "8               6.848485  0.000002          0.000000           1          1   \n",
       "\n",
       "      closeness  betweenness  time_step  trans_feat_0  trans_feat_1  ...  \\\n",
       "txId                                                                 ...   \n",
       "537    0.155365       2355.0          1      0.163054      1.963790  ...   \n",
       "4133   0.134193       1223.0          1     -0.005027      0.578941  ...   \n",
       "5      0.099405          0.0          1     -0.147852     -0.184668  ...   \n",
       "5187   0.110372          7.0          1     -0.151357     -0.184668  ...   \n",
       "8      0.139805          4.0          1     -0.172306     -0.184668  ...   \n",
       "\n",
       "      agg_feat_62  agg_feat_63  agg_feat_64  agg_feat_65  agg_feat_66  \\\n",
       "txId                                                                    \n",
       "537     -0.577099    -0.613614     0.241128     0.241406     1.072793   \n",
       "4133    -0.577099    -0.613614     0.241128     0.241406     0.604120   \n",
       "5       -0.577099    -0.613614     0.241128     0.241406     0.018279   \n",
       "5187    -0.539735    -0.582077    -0.979074    -0.978556     0.018279   \n",
       "8       -0.577099    -0.600999     0.241128     0.241406     0.018279   \n",
       "\n",
       "      agg_feat_67  agg_feat_68  agg_feat_69  agg_feat_70  agg_feat_71  \n",
       "txId                                                                   \n",
       "537      0.085530    -0.131155     0.677799    -0.120613    -0.119792  \n",
       "4133     0.008632    -0.131155     0.333211    -0.120613    -0.119792  \n",
       "5       -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "5187    -0.087490    -0.131155    -0.097524    -0.120613    -0.119792  \n",
       "8       -0.068266    -0.084674    -0.054450    -1.760926    -1.760984  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform the dataframe in a suitable input for KMeans. We drop the columns containing\n",
    "#the correct labels\n",
    "df.drop(df[df[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "\n",
    "y = df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "#X = X.loc[:, 'time_step':'trans_feat_92']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['time_step'].between(1, 34)]\n",
    "y_train = y[X['time_step'].between(1, 34)]\n",
    "\n",
    "X_test = X[X['time_step'].between(35, 49)]\n",
    "y_test = y[X['time_step'].between(35, 49)]\n",
    "\n",
    "#X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "#X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "#X_train = X_train.reset_index(drop=True)\n",
    "#y_train = y_train.reset_index(drop=True)\n",
    "#X_test = X_test.reset_index(drop=True)\n",
    "#y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29894, 173)\n",
      "(16670, 173)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LF = X_train.loc[:, 'time_step':'trans_feat_92']\n",
    "X_test_LF = X_test.loc[:, 'time_step':'trans_feat_92']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_LF.fit(X_train_LF, y_train)\n",
    "y_pred_LF = clf_LF.predict(X_test_LF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision local features: 0.8954022988505748\n",
      "Recall local features: 0.7192982456140351\n",
      "F1 local features: 0.7977470558115719\n",
      "Cross-validated F1 Score local features: 0.8165668043629909\n"
     ]
    }
   ],
   "source": [
    "precision_ilicit_lf = precision_score(y_test, y_pred_LF, pos_label='1')\n",
    "recall_ilicit_lf = recall_score(y_test, y_pred_LF, pos_label='1')\n",
    "f1_ilicit_lf = f1_score(y_test, y_pred_LF, pos_label='1')\n",
    "f1_scorer_lf = make_scorer(f1_score, pos_label='1')\n",
    "scores_lf = cross_val_score(clf_LF, X_train_LF, y_train, cv=5, scoring=f1_scorer_lf)\n",
    "\n",
    "print(f'Precision local features: {precision_ilicit_lf}')\n",
    "print(f'Recall local features: {recall_ilicit_lf}')\n",
    "print(f'F1 local features: {f1_ilicit_lf}')\n",
    "print(\"Cross-validated F1 Score local features:\", scores_lf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_AF = X_train.loc[:, 'time_step':]\n",
    "X_test_AF = X_test.loc[:, 'time_step':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_AF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_AF.fit(X_train_AF, y_train)\n",
    "y_pred_AF = clf_AF.predict(X_test_AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision all features: 0.9630996309963099\n",
      "Recall all features: 0.7229916897506925\n",
      "F1 all features: 0.8259493670886076\n",
      "Cross-validated F1 Score all features: 0.7669789086780978\n"
     ]
    }
   ],
   "source": [
    "precision_ilicit_af = precision_score(y_test, y_pred_AF, pos_label='1')\n",
    "recall_ilicit_af = recall_score(y_test, y_pred_AF, pos_label='1')\n",
    "f1_ilicit_af = f1_score(y_test, y_pred_AF, pos_label='1')\n",
    "f1_scorer_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_af = cross_val_score(clf_AF, X_train_AF, y_train, cv=5, scoring=f1_scorer_af)\n",
    "\n",
    "print(f'Precision all features: {precision_ilicit_af}')\n",
    "print(f'Recall all features: {recall_ilicit_af}')\n",
    "print(f'F1 all features: {f1_ilicit_af}')\n",
    "print(\"Cross-validated F1 Score all features:\", scores_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Features + Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LF_NF = X_train.loc[:, :'trans_feat_92']\n",
    "X_test_LF_NF = X_test.loc[:, :'trans_feat_92']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LF_NF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_LF_NF.fit(X_train_LF_NF, y_train)\n",
    "y_pred_LF_NF = clf_LF_NF.predict(X_test_LF_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision local features + node features: 0.8834285714285715\n",
      "Recall local features + node features: 0.7137580794090489\n",
      "F1 local features + node features: 0.7895812053115424\n",
      "Cross-validated F1 Score local features + node featuress: 0.806622062346286\n"
     ]
    }
   ],
   "source": [
    "precision_ilicit_lf_nf = precision_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "recall_ilicit_lf_nf = recall_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "f1_ilicit_lf_nf = f1_score(y_test, y_pred_LF_NF, pos_label='1')\n",
    "f1_scorer_lf_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_lf_nf = cross_val_score(clf_LF_NF, X_train_LF_NF, y_train, cv=5, scoring=f1_scorer_lf_nf)\n",
    "\n",
    "print(f'Precision local features + node features: {precision_ilicit_lf_nf}')\n",
    "print(f'Recall local features + node features: {recall_ilicit_lf_nf}')\n",
    "print(f'F1 local features + node features: {f1_ilicit_lf_nf}')\n",
    "print(\"Cross-validated F1 Score local features + node featuress:\", scores_lf_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features + Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_AF_NF = X_train.loc[:, :]\n",
    "X_test_AF_NF = X_test.loc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_AF_NF = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_AF_NF.fit(X_train_AF_NF, y_train)\n",
    "y_pred_AF_NF = clf_AF_NF.predict(X_test_AF_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision all features + node features: 0.9688667496886675\n",
      "Recall all features + node features: 0.7183748845798708\n",
      "F1 all features + node features: 0.8250265111346765\n",
      "Cross-validated F1 Score all features + node featuress: 0.7656639355052065\n"
     ]
    }
   ],
   "source": [
    "precision_ilicit_af_nf = precision_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "recall_ilicit_af_nf = recall_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "f1_ilicit_af_nf = f1_score(y_test, y_pred_AF_NF, pos_label='1')\n",
    "f1_scorer_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_af_nf = cross_val_score(clf_AF_NF, X_train_AF_NF, y_train, cv=5, scoring=f1_scorer_af_nf)\n",
    "\n",
    "print(f'Precision all features + node features: {precision_ilicit_af_nf}')\n",
    "print(f'Recall all features + node features: {recall_ilicit_af_nf}')\n",
    "print(f'F1 all features + node features: {f1_ilicit_af_nf}')\n",
    "print(\"Cross-validated F1 Score all features + node featuress:\", scores_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Embeddings (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision node embeddings (GCN): 0.7414448669201521\n",
      "Recall node embeddings (GCN): 0.18005540166204986\n",
      "F1 node embeddings (GCN): 0.2897473997028232\n",
      "Cross-validated F1 Score node embeddings (GCN): 0.5190787027336995\n"
     ]
    }
   ],
   "source": [
    "embeddings = pd.read_csv('../data/embeddings_gcn.csv')\n",
    "embeddings.drop(embeddings[embeddings[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings\n",
    "\n",
    "y_gcn = embeddings['label']\n",
    "X_gcn = embeddings.drop(columns=['label'])\n",
    "\n",
    "X_train_gcn = X_gcn[X_gcn['time_step'].between(1, 34)]\n",
    "y_train_gcn = y_gcn[X_gcn['time_step'].between(1, 34)]\n",
    "  \n",
    "X_test_gcn = X_gcn[X_gcn['time_step'].between(35, 49)]\n",
    "y_test_gcn = y_gcn[X_gcn['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gcn = X_train_gcn.loc[:, '0':'127']\n",
    "X_test_gcn = X_test_gcn.loc[:, '0':'127']\n",
    "\n",
    "clf_gcn = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gcn.fit(X_train_gcn, y_train_gcn)\n",
    "y_pred_gcn = clf_gcn.predict(X_test_gcn)\n",
    "\n",
    "precision_ilicit_gcn = precision_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "recall_ilicit_gcn = recall_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "f1_ilicit_gcn = f1_score(y_test_gcn, y_pred_gcn, pos_label='1')\n",
    "f1_scorer_gcn = make_scorer(f1_score, pos_label='1')\n",
    "scores_gcn = cross_val_score(clf_gcn, X_train_gcn, y_train_gcn, cv=5, scoring=f1_scorer_gcn)\n",
    "\n",
    "print(f'Precision node embeddings (GCN): {precision_ilicit_gcn}')\n",
    "print(f'Recall node embeddings (GCN): {recall_ilicit_gcn}')\n",
    "print(f'F1 node embeddings (GCN): {f1_ilicit_gcn}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GCN):\", scores_gcn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings + Local Features (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + local features: 0.9634941329856584\n",
      "Recall embeddings + local features: 0.6823638042474608\n",
      "F1 embeddings + local features: 0.798918918918919\n",
      "Cross-validated F1 Score embeddings + local features: 0.8580969080097169\n"
     ]
    }
   ],
   "source": [
    "df_ne_lf = df.loc[:, 'time_step':'trans_feat_92'].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_lf = df_ne_lf.drop(columns=['label'])\n",
    "y_ne_lf = df_ne_lf['label']\n",
    "\n",
    "X_train_ne_lf = X_ne_lf[X_ne_lf['time_step'].between(1, 34)]\n",
    "y_train_ne_lf = y_ne_lf[X_ne_lf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_lf = X_ne_lf[X_ne_lf['time_step'].between(35, 49)]\n",
    "y_test_ne_lf = y_ne_lf[X_ne_lf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_lf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_lf.fit(X_train_ne_lf, y_train_ne_lf)\n",
    "y_pred_ne_lf = clf_ne_lf.predict(X_test_ne_lf)\n",
    "\n",
    "precision_ilicit_ne_lf = precision_score(y_test_ne_lf, y_pred_ne_lf, pos_label='1')\n",
    "recall_ilicit_ne_lf = recall_score(y_test_ne_lf, y_pred_ne_lf, pos_label='1')\n",
    "f1_ilicit_ne_lf = f1_score(y_test_ne_lf, y_pred_ne_lf, pos_label='1')\n",
    "f1_scorer_ne_lf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_lf = cross_val_score(clf_ne_lf, X_train_ne_lf, y_train_ne_lf, cv=5, scoring=f1_scorer_ne_lf)\n",
    "\n",
    "print(f'Precision embeddings + local features: {precision_ilicit_ne_lf}')\n",
    "print(f'Recall embeddings + local features: {recall_ilicit_ne_lf}')\n",
    "print(f'F1 embeddings + local features: {f1_ilicit_ne_lf}')\n",
    "print(\"Cross-validated F1 Score embeddings + local features:\", scores_ne_lf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings + All Features (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features: 0.9676584734799483\n",
      "Recall embeddings + all features: 0.6906740535549399\n",
      "F1 embeddings + all features: 0.8060344827586207\n",
      "Cross-validated F1 Score embeddings + all features: 0.748979196240978\n"
     ]
    }
   ],
   "source": [
    "df_ne_af = df.loc[:, 'time_step':].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_af = df_ne_af.drop(columns=['label'])\n",
    "y_ne_af = df_ne_af['label']\n",
    "\n",
    "X_train_ne_af = X_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "y_train_ne_af = y_ne_af[X_ne_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af = X_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "y_test_ne_af = y_ne_af[X_ne_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af.fit(X_train_ne_af, y_train_ne_af)\n",
    "y_pred_ne_af = clf_ne_af.predict(X_test_ne_af)\n",
    "\n",
    "precision_ilicit_ne_af = precision_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "recall_ilicit_ne_af = recall_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_ilicit_ne_af = f1_score(y_test_ne_af, y_pred_ne_af, pos_label='1')\n",
    "f1_scorer_ne_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af = cross_val_score(clf_ne_af, X_train_ne_af, y_train_ne_af, cv=5, scoring=f1_scorer_ne_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_ne_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_ne_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_ne_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Features + Embeddings (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + node features: 0.6827309236947792\n",
      "Recall embeddings + node features: 0.1569713758079409\n",
      "F1 embeddings + node features: 0.2552552552552553\n",
      "Cross-validated F1 Score embeddings + node features: 0.43187246048124434\n"
     ]
    }
   ],
   "source": [
    "df_ne_nf = df.loc[:, 'avg_shortest_paths':'time_step'].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "X_ne_nf = df_ne_nf.drop(columns=['label'])\n",
    "y_ne_nf = df_ne_nf['label']\n",
    "\n",
    "X_train_ne_nf = X_ne_nf[X_ne_nf['time_step'].between(1, 34)]\n",
    "y_train_ne_nf = y_ne_nf[X_ne_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_nf = X_ne_nf[X_ne_nf['time_step'].between(35, 49)]\n",
    "y_test_ne_nf = y_ne_nf[X_ne_nf['time_step'].between(35, 49)]\n",
    "\n",
    "cnf_ne_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "cnf_ne_nf.fit(X_train_ne_nf, y_train_ne_nf)\n",
    "y_pred_ne_nf = cnf_ne_nf.predict(X_test_ne_nf)\n",
    "\n",
    "precision_ilicit_ne_nf = precision_score(y_test_ne_nf, y_pred_ne_nf, pos_label='1')\n",
    "recall_ilicit_ne_nf = recall_score(y_test_ne_nf, y_pred_ne_nf, pos_label='1')\n",
    "f1_ilicit_ne_nf = f1_score(y_test_ne_nf, y_pred_ne_nf, pos_label='1')\n",
    "f1_scorer_ne_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_nf = cross_val_score(cnf_ne_nf, X_train_ne_nf, y_train_ne_nf, cv=5, scoring=f1_scorer_ne_nf)\n",
    "\n",
    "print(f'Precision embeddings + node features: {precision_ilicit_ne_nf}')\n",
    "print(f'Recall embeddings + node features: {recall_ilicit_ne_nf}')\n",
    "print(f'F1 embeddings + node features: {f1_ilicit_ne_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + node features:\", scores_ne_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings + All Features + Node Features (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features + node features: 0.970886075949367\n",
      "Recall embeddings + all features + node features: 0.7082179132040628\n",
      "F1 embeddings + all features + node features: 0.8190069407367859\n",
      "Cross-validated F1 Score embeddings + all features: 0.7526586640000011\n"
     ]
    }
   ],
   "source": [
    "#df_ne_af_nf = df.loc[:,:].join(embeddings.drop(columns=['time_step']).set_index('txId'))\n",
    "df_ne_af_nf = df.loc[:,:].join(embeddings.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_ne_af_nf = df_ne_af_nf.drop(columns=['label'])\n",
    "y_ne_af_nf = df_ne_af_nf['label']\n",
    "\n",
    "X_train_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "y_train_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_ne_af_nf = X_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "y_test_ne_af_nf = y_ne_af_nf[X_ne_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_ne_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_ne_af_nf.fit(X_train_ne_af_nf, y_train_ne_af_nf)\n",
    "y_pred_ne_af_nf = clf_ne_af_nf.predict(X_test_ne_af_nf)\n",
    "\n",
    "precision_ilicit_ne_af_nf = precision_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "recall_ilicit_ne_af_nf = recall_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_ilicit_ne_af_nf = f1_score(y_test_ne_af_nf, y_pred_ne_af_nf, pos_label='1')\n",
    "f1_scorer_ne_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_ne_af_nf = cross_val_score(clf_ne_af_nf, X_train_ne_af_nf, y_train_ne_af_nf, cv=5, scoring=f1_scorer_ne_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_ne_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_ne_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_ne_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_ne_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Emebddings (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision node embeddings (GAT): 0.7008797653958945\n",
      "Recall node embeddings (GAT): 0.22068328716528163\n",
      "F1 node embeddings (GAT): 0.3356741573033708\n",
      "Cross-validated F1 Score node embeddings (GAT): 0.3383593260780247\n"
     ]
    }
   ],
   "source": [
    "embeddings_gat = pd.read_csv('../data/embeddings_gat.csv')\n",
    "\n",
    "embeddings_gat.drop(embeddings_gat[embeddings_gat[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings_gat\n",
    "\n",
    "y_gat = embeddings_gat['label']\n",
    "X_gat = embeddings_gat.drop(columns=['label'])\n",
    "\n",
    "X_train_gat = X_gat[X_gat['time_step'].between(1, 34)]\n",
    "y_train_gat = y_gat[X_gat['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gat = X_gat[X_gat['time_step'].between(35, 49)]\n",
    "y_test_gat = y_gat[X_gat['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gat = X_train_gat.loc[:, '0':'127']\n",
    "X_test_gat = X_test_gat.loc[:, '0':'127']\n",
    "\n",
    "clf_gat = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gat.fit(X_train_gat, y_train_gat)\n",
    "y_pred_gat = clf_gat.predict(X_test_gat)\n",
    "\n",
    "precision_ilicit_gat = precision_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "recall_ilicit_gat = recall_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "f1_ilicit_gat = f1_score(y_test_gat, y_pred_gat, pos_label='1')\n",
    "f1_scorer_gat = make_scorer(f1_score, pos_label='1')\n",
    "scores_gat = cross_val_score(clf_gat, X_train_gat, y_train_gat, cv=5, scoring=f1_scorer_gat)\n",
    "\n",
    "print(f'Precision node embeddings (GAT): {precision_ilicit_gat}')\n",
    "print(f'Recall node embeddings (GAT): {recall_ilicit_gat}')\n",
    "print(f'F1 node embeddings (GAT): {f1_ilicit_gat}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GAT):\", scores_gat.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features: 0.9617834394904459\n",
      "Recall embeddings + all features: 0.6971375807940905\n",
      "F1 embeddings + all features: 0.8083511777301927\n",
      "Cross-validated F1 Score embeddings + all features: 0.6564497492777985\n"
     ]
    }
   ],
   "source": [
    "df_gat_af = df.loc[:, 'time_step':].join(embeddings_gat.drop(columns=['time_step']).set_index('txId'))\n",
    "X_gat_af = df_gat_af.drop(columns=['label'])\n",
    "y_gat_af = df_gat_af['label']\n",
    "\n",
    "X_train_gat_af = X_gat_af[X_gat_af['time_step'].between(1, 34)]\n",
    "y_train_gat_af = y_gat_af[X_gat_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gat_af = X_gat_af[X_gat_af['time_step'].between(35, 49)]\n",
    "y_test_gat_af = y_gat_af[X_gat_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_gat_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gat_af.fit(X_train_gat_af, y_train_gat_af)\n",
    "y_pred_gat_af = clf_gat_af.predict(X_test_gat_af)\n",
    "\n",
    "precision_ilicit_gat_af = precision_score(y_test_gat_af, y_pred_gat_af, pos_label='1')\n",
    "recall_ilicit_gat_af = recall_score(y_test_gat_af, y_pred_gat_af, pos_label='1')\n",
    "f1_ilicit_gat_af = f1_score(y_test_gat_af, y_pred_gat_af, pos_label='1')\n",
    "f1_scorer_gat_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_gat_af = cross_val_score(clf_gat_af, X_train_gat_af, y_train_gat_af, cv=5, scoring=f1_scorer_gat_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_gat_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_gat_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_gat_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_gat_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features + Node Features (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features + node features: 0.9641025641025641\n",
      "Recall embeddings + all features + node features: 0.6943674976915974\n",
      "F1 embeddings + all features + node features: 0.8073000536768653\n",
      "Cross-validated F1 Score embeddings + all features: 0.6495020825760126\n"
     ]
    }
   ],
   "source": [
    "df_gat_af_nf = df.loc[:,:].join(embeddings_gat.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_gat_af_nf = df_gat_af_nf.drop(columns=['label'])\n",
    "y_gat_af_nf = df_gat_af_nf['label']\n",
    "\n",
    "X_train_gat_af_nf = X_gat_af_nf[X_gat_af_nf['time_step'].between(1, 34)]\n",
    "y_train_gat_af_nf = y_gat_af_nf[X_gat_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gat_af_nf = X_gat_af_nf[X_gat_af_nf['time_step'].between(35, 49)]\n",
    "y_test_gat_af_nf = y_gat_af_nf[X_gat_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_gat_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gat_af_nf.fit(X_train_gat_af_nf, y_train_gat_af_nf)\n",
    "y_pred_gat_af_nf = clf_gat_af_nf.predict(X_test_gat_af_nf)\n",
    "\n",
    "precision_ilicit_gat_af_nf = precision_score(y_test_gat_af_nf, y_pred_gat_af_nf, pos_label='1')\n",
    "recall_ilicit_gat_af_nf = recall_score(y_test_gat_af_nf, y_pred_gat_af_nf, pos_label='1')\n",
    "f1_ilicit_gat_af_nf = f1_score(y_test_gat_af_nf, y_pred_gat_af_nf, pos_label='1')\n",
    "f1_scorer_gat_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_gat_af_nf = cross_val_score(clf_gat_af_nf, X_train_gat_af_nf, y_train_gat_af_nf, cv=5, scoring=f1_scorer_gat_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_gat_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_gat_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_gat_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_gat_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Emebddings (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision node embeddings (GIN): 0.6507177033492823\n",
      "Recall node embeddings (GIN): 0.3767313019390582\n",
      "F1 node embeddings (GIN): 0.47719298245614034\n",
      "Cross-validated F1 Score node embeddings (GIN): 0.712725909464736\n"
     ]
    }
   ],
   "source": [
    "embeddings_gin = pd.read_csv('../data/embeddings_gin1.csv')\n",
    "\n",
    "embeddings_gin.drop(embeddings_gin[embeddings_gin[\"label\"] == \"unknown\"].index, inplace=True)\n",
    "embeddings_gin\n",
    "\n",
    "y_gin = embeddings_gin['label']\n",
    "X_gin = embeddings_gin.drop(columns=['label'])\n",
    "\n",
    "X_train_gin = X_gin[X_gin['time_step'].between(1, 34)]\n",
    "y_train_gin = y_gin[X_gin['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gin = X_gin[X_gin['time_step'].between(35, 49)]\n",
    "y_test_gin = y_gin[X_gin['time_step'].between(35, 49)]\n",
    "\n",
    "X_train_gin = X_train_gin.loc[:, '0':'127']\n",
    "X_test_gin = X_test_gin.loc[:, '0':'127']\n",
    "\n",
    "clf_gin = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gin.fit(X_train_gin, y_train_gin)\n",
    "y_pred_gin = clf_gin.predict(X_test_gin)\n",
    "\n",
    "precision_ilicit_gin = precision_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "recall_ilicit_gin = recall_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "f1_ilicit_gin = f1_score(y_test_gin, y_pred_gin, pos_label='1')\n",
    "f1_scorer_gin = make_scorer(f1_score, pos_label='1')\n",
    "scores_gin = cross_val_score(clf_gin, X_train_gin, y_train_gin, cv=5, scoring=f1_scorer_gin)\n",
    "\n",
    "print(f'Precision node embeddings (GIN): {precision_ilicit_gin}')\n",
    "print(f'Recall node embeddings (GIN): {recall_ilicit_gin}')\n",
    "print(f'F1 node embeddings (GIN): {f1_ilicit_gin}')\n",
    "print(\"Cross-validated F1 Score node embeddings (GIN):\", scores_gin.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Node Embeddings + All Features (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features: 0.9553805774278216\n",
      "Recall embeddings + all features: 0.6722068328716528\n",
      "F1 embeddings + all features: 0.789159891598916\n",
      "Cross-validated F1 Score embeddings + all features: 0.6918800159987136\n"
     ]
    }
   ],
   "source": [
    "df_gin_af = df.loc[:, 'time_step':].join(embeddings_gin.drop(columns=['time_step']).set_index('txId'))\n",
    "X_gin_af = df_gin_af.drop(columns=['label'])\n",
    "y_gin_af = df_gin_af['label']\n",
    "\n",
    "X_train_gin_af = X_gin_af[X_gin_af['time_step'].between(1, 34)]\n",
    "y_train_gin_af = y_gin_af[X_gin_af['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gin_af = X_gin_af[X_gin_af['time_step'].between(35, 49)]\n",
    "y_test_gin_af = y_gin_af[X_gin_af['time_step'].between(35, 49)]\n",
    "\n",
    "clf_gin_af = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gin_af.fit(X_train_gin_af, y_train_gin_af)\n",
    "y_pred_gin_af = clf_gin_af.predict(X_test_gin_af)\n",
    "\n",
    "precision_ilicit_gin_af = precision_score(y_test_gin_af, y_pred_gin_af, pos_label='1')\n",
    "recall_ilicit_gin_af = recall_score(y_test_gin_af, y_pred_gin_af, pos_label='1')\n",
    "f1_ilicit_gin_af = f1_score(y_test_gin_af, y_pred_gin_af, pos_label='1')\n",
    "f1_scorer_gin_af = make_scorer(f1_score, pos_label='1')\n",
    "scores_gin_af = cross_val_score(clf_gin_af, X_train_gin_af, y_train_gin_af, cv=5, scoring=f1_scorer_gin_af)\n",
    "\n",
    "print(f'Precision embeddings + all features: {precision_ilicit_gin_af}')\n",
    "print(f'Recall embeddings + all features: {recall_ilicit_gin_af}')\n",
    "print(f'F1 embeddings + all features: {f1_ilicit_gin_af}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_gin_af.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings + All Features + Node Features (GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision embeddings + all features + node features: 0.9421813403416557\n",
      "Recall embeddings + all features + node features: 0.6620498614958449\n",
      "F1 embeddings + all features + node features: 0.7776572668112798\n",
      "Cross-validated F1 Score embeddings + all features: 0.7141989956121124\n"
     ]
    }
   ],
   "source": [
    "df_gin_af_nf = df.loc[:,:].join(embeddings_gin.drop(columns=['time_step', 'label']).set_index('txId'))\n",
    "X_gin_af_nf = df_gin_af_nf.drop(columns=['label'])\n",
    "y_gin_af_nf = df_gin_af_nf['label']\n",
    "\n",
    "X_train_gin_af_nf = X_gin_af_nf[X_gin_af_nf['time_step'].between(1, 34)]\n",
    "y_train_gin_af_nf = y_gin_af_nf[X_gin_af_nf['time_step'].between(1, 34)]\n",
    "\n",
    "X_test_gin_af_nf = X_gin_af_nf[X_gin_af_nf['time_step'].between(35, 49)]\n",
    "y_test_gin_af_nf = y_gin_af_nf[X_gin_af_nf['time_step'].between(35, 49)]\n",
    "\n",
    "clf_gin_af_nf = RandomForestClassifier(n_estimators = 100, random_state=42)  \n",
    "clf_gin_af_nf.fit(X_train_gin_af_nf, y_train_gin_af_nf)\n",
    "y_pred_gin_af_nf = clf_gin_af_nf.predict(X_test_gin_af_nf)\n",
    "\n",
    "precision_ilicit_gin_af_nf = precision_score(y_test_gin_af_nf, y_pred_gin_af_nf, pos_label='1')\n",
    "recall_ilicit_gin_af_nf = recall_score(y_test_gin_af_nf, y_pred_gin_af_nf, pos_label='1')\n",
    "f1_ilicit_gin_af_nf = f1_score(y_test_gin_af_nf, y_pred_gin_af_nf, pos_label='1')\n",
    "f1_scorer_gin_af_nf = make_scorer(f1_score, pos_label='1')\n",
    "scores_gin_af_nf = cross_val_score(clf_gin_af_nf, X_train_gin_af_nf, y_train_gin_af_nf, cv=5, scoring=f1_scorer_gin_af_nf)\n",
    "\n",
    "print(f'Precision embeddings + all features + node features: {precision_ilicit_gin_af_nf}')\n",
    "print(f'Recall embeddings + all features + node features: {recall_ilicit_gin_af_nf}')\n",
    "print(f'F1 embeddings + all features + node features: {f1_ilicit_gin_af_nf}')\n",
    "print(\"Cross-validated F1 Score embeddings + all features:\", scores_gin_af_nf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1569066306.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    class_index_af = clf_AF.classes_.tolist().index('1')  F\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_test_binary = (y_test == '1').astype(int)\n",
    "\n",
    "class_index_lf = clf_LF.classes_.tolist().index('1')  \n",
    "y_prob_lf = clf_LF.predict_proba(X_test_LF)[:, class_index_lf]\n",
    "\n",
    "class_index_af = clf_AF.classes_.tolist().index('1')  F\n",
    "y_prob_af = clf_AF.predict_proba(X_test_AF)[:, class_index_af]\n",
    "\n",
    "class_index_lf_nf = clf_LF_NF.classes_.tolist().index('1')  \n",
    "y_prob_lf_nf = clf_LF_NF.predict_proba(X_test_LF_NF)[:, class_index_lf_nf]\n",
    "\n",
    "class_index_af_nf = clf_AF_NF.classes_.tolist().index('1')  \n",
    "y_prob_af_nf = clf_AF_NF.predict_proba(X_test_AF_NF)[:, class_index_af_nf]\n",
    "\n",
    "class_index_ne_af = clf_ne_af.classes_.tolist().index('1')  \n",
    "y_prob_ne_af = clf_ne_af.predict_proba(X_test_ne_af)[:, class_index_ne_af]\n",
    "\n",
    "class_index_ne_af_nf = clf_ne_af_nf.classes_.tolist().index('1')  \n",
    "y_prob_ne_af_nf = clf_ne_af_nf.predict_proba(X_test_ne_af_nf)[:, class_index_ne_af_nf]\n",
    "\n",
    "fpr_lf, tpr_lf, thresholds_lf = roc_curve(y_test, y_prob_lf, pos_label='1')\n",
    "fpr_af, tpr_af, thresholds_af = roc_curve(y_test, y_prob_af, pos_label='1')\n",
    "fpr_lf_nf, tpr_lf_nf, thresholds_lf_nf = roc_curve(y_test, y_prob_lf_nf, pos_label='1')\n",
    "fpr_af_nf, tpr_af_nf, thresholds_af_nf = roc_curve(y_test, y_prob_af_nf, pos_label='1')\n",
    "fpr_ne_af, tpr_ne_af, thresholds_ne_af = roc_curve(y_test, y_prob_ne_af, pos_label='1')\n",
    "fpr_ne_af_nf, tpr_ne_af_nf, thresholds_ne_af_nf = roc_curve(y_test, y_prob_ne_af_nf, pos_label='1')\n",
    "\n",
    "roc_auc_lf = roc_auc_score(y_test_binary, y_prob_lf)\n",
    "print(f\"ROC-AUC Score for illicit (Local Features): {roc_auc_lf:.3f}\")\n",
    "\n",
    "roc_auc_af = roc_auc_score(y_test_binary, y_prob_af)\n",
    "print(f\"ROC-AUC Score for illicit (All Features): {roc_auc_af:.3f}\")\n",
    "\n",
    "roc_auc_lf_nf = roc_auc_score(y_test_binary, y_prob_lf_nf)\n",
    "print(f\"ROC-AUC Score for illicit (Local Features + Node Features): {roc_auc_lf_nf:.3f}\")\n",
    "\n",
    "roc_auc_af_nf = roc_auc_score(y_test_binary, y_prob_af_nf)\n",
    "print(f\"ROC-AUC Score for illicit (All Features + Node Features): {roc_auc_af_nf:.3f}\")\n",
    "\n",
    "roc_auc_ne_af = roc_auc_score(y_test_binary, y_prob_ne_af)\n",
    "print(f\"ROC-AUC Score for illicit (Node Embeddings + All features (GCN)): {roc_auc_ne_af:.3f}\")\n",
    "\n",
    "roc_auc_ne_af_nf = roc_auc_score(y_test_binary, y_prob_ne_af_nf)\n",
    "print(f\"ROC-AUC Score for illicit (Embeddings + All Features + Node Features (GCN)): {roc_auc_ne_af_nf:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lf, tpr_lf, label=f\"ROC Curve (AUC = {roc_auc_lf:.3f}) for illicit lf\")\n",
    "plt.plot(fpr_af, tpr_af, label=f\"ROC Curve (AUC = {roc_auc_af:.3f}) for illicit af\")\n",
    "plt.plot(fpr_lf_nf, tpr_lf_nf, label=f\"ROC Curve (AUC = {roc_auc_lf_nf:.3f}) for illicit nf+lf\")\n",
    "plt.plot(fpr_af_nf, tpr_af_nf, label=f\"ROC Curve (AUC = {roc_auc_af_nf:.3f}) for illicit af+nf\")\n",
    "plt.plot(fpr_ne_af, tpr_ne_af, label=f\"ROC Curve (AUC = {roc_auc_ne_af:.3f}) for illicit ne+af (GCN)\")\n",
    "plt.plot(fpr_ne_af_nf, tpr_ne_af_nf, label=f\"ROC Curve (AUC = {roc_auc_ne_af_nf:.3f}) for illicit embeddings+af+nf (GCN)\")\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', alpha=0.6, label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for illicit\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#importances = clf.feature_importances_\n",
    "#features = X.columns  \n",
    "\n",
    "#feature_importances = pd.DataFrame({\n",
    "#    'Feature': features,\n",
    "#    'Importance': importances\n",
    "#})\n",
    "\n",
    "#feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "#top_features = feature_importances.head(50)\n",
    "\n",
    "#print(top_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#fig, ax = plt.subplots(figsize=(20, 20)) \n",
    "#node_sizes = [c * 50 for c in centralities]\n",
    "#layout = tx_graph.layout_fruchterman_reingold()\n",
    "#ig.plot(tx_graph, vertex_size=node_sizes, vertex_frame_width=0.5, edge_width=0.1, bbox=(8000, 8000), margin=50, target=ax)\n",
    "#plt.savefig(\"large_graph.png\", dpi=300)\n",
    "#plt.savefig(\"large_graph.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#undirected_graph = tx_graph.as_undirected(combine_edges=None)\n",
    "#ilicit_indices = [v.index for v in undirected_graph.vs if v['type'] == '1']\n",
    "#ilicit_graph = undirected_graph.induced_subgraph(ilicit_indices)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(20, 20)) \n",
    "#ilicit_centralities = ilicit_graph.closeness()\n",
    "#node_sizes = [c * 50 for c in centralities]\n",
    "#layout = ilicit_graph.layout_fruchterman_reingold()\n",
    "#ig.plot(ilicit_graph, vertex_size=node_sizes, vertex_frame_width=0.5, edge_width=0.1, bbox=(8000, 8000), margin=50, target=ax)\n",
    "#plt.savefig(\"ilicit_graph.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = df['time_step']\n",
    "\n",
    "grouped_data = df.groupby(['time_step', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "colors = ['#FF0707', '#08E634', 'lightblue']\n",
    "grouped_data.plot(kind='bar', figsize=(12, 6), width=0.8, edgecolor='black', color=colors)\n",
    "\n",
    "plt.title('Licit and ilicit operations through time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('# of operations')\n",
    "plt.xticks(range(4, 50, 5), rotation=0)\n",
    "plt.legend(labels=['illicit', 'licit', 'unknown'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.axvline(x=22, color='black', linestyle='--', linewidth=1, label='Time Step 29')\n",
    "plt.axvline(x=33, color='black', linestyle='--', linewidth=1, label='Time Step 34')\n",
    "\n",
    "plt.savefig('timesteps.png', format='png', dpi=300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "illicit_data = df[df['label'] == '1']\n",
    "\n",
    "grouped_illicit = illicit_data.groupby('time_step').size()\n",
    "\n",
    "grouped_illicit.plot(kind='bar', figsize=(12, 6), width=0.8, edgecolor='lightblue', color='lightblue')\n",
    "\n",
    "plt.title('Illicit Operations Through Time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('# of Illicit Operations')\n",
    "plt.xticks(range(4, 50, 5), rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_by_time_lf = []\n",
    "precision_by_time_af = []\n",
    "precision_by_time_lf_nf = []\n",
    "precision_by_time_af_nf = []\n",
    "precision_by_time_ne_af = []\n",
    "precision_by_time_ne_af_nf = []\n",
    "precision_by_time_gat_af = []\n",
    "precision_by_time_gat_af_nf = []\n",
    "\n",
    "time_steps = sorted(df[df['time_step'] >= 35]['time_step'].unique())\n",
    "\n",
    "for step in time_steps:\n",
    "    y_true = y_test[X_test['time_step'] == step]  \n",
    "    \n",
    "    y_pred_step_lf = y_pred_LF[X_test['time_step'] == step]\n",
    "    y_pred_step_af = y_pred_AF[X_test['time_step'] == step]\n",
    "    y_pred_step_lf_nf = y_pred_LF_NF[X_test['time_step'] == step]\n",
    "    y_pred_step_af_nf = y_pred_AF_NF[X_test['time_step'] == step]\n",
    "    y_pred_step_ne_af = y_pred_ne_af[X_test['time_step'] == step]\n",
    "    y_pred_step_ne_af_nf = y_pred_ne_af_nf[X_test['time_step'] == step]\n",
    "    y_pred_step_gat_af = y_pred_gat_af[X_test['time_step'] == step]\n",
    "    y_pred_step_gat_af_nf = y_pred_gat_af_nf[X_test['time_step'] == step]\n",
    "    \n",
    "\n",
    "    if len(y_true) > 0:  \n",
    "        precision_lf = precision_score(y_true, y_pred_step_lf, pos_label='1', zero_division=0)\n",
    "        precision_af = precision_score(y_true, y_pred_step_af, pos_label='1', zero_division=0)\n",
    "        precision_lf_nf = precision_score(y_true, y_pred_step_lf_nf, pos_label='1', zero_division=0)\n",
    "        precision_af_nf = precision_score(y_true, y_pred_step_af_nf, pos_label='1', zero_division=0)\n",
    "        precision_ne_af = precision_score(y_true, y_pred_step_ne_af, pos_label='1', zero_division=0)\n",
    "        precision_ne_af_nf = precision_score(y_true, y_pred_step_ne_af_nf, pos_label='1', zero_division=0)\n",
    "        precision_gat_af = precision_score(y_true, y_pred_step_gat_af, pos_label='1', zero_division=0)\n",
    "        precision_gat_af_nf = precision_score(y_true, y_pred_step_gat_af_nf, pos_label='1', zero_division=0)\n",
    "        \n",
    "        precision_by_time_lf.append(precision_lf)\n",
    "        precision_by_time_af.append(precision_af)\n",
    "        precision_by_time_lf_nf.append(precision_lf_nf)\n",
    "        precision_by_time_af_nf.append(precision_af_nf)\n",
    "        precision_by_time_ne_af.append(precision_ne_af_nf)\n",
    "        precision_by_time_ne_af_nf.append(precision_ne_af_nf)\n",
    "        precision_by_time_gat_af.append(precision_gat_af_nf)\n",
    "        precision_by_time_gat_af_nf.append(precision_gat_af_nf)\n",
    "    else:\n",
    "        precision_by_time_lf.append(0)  \n",
    "        precision_by_time_af.append(0)\n",
    "        precision_by_time_lf_nf.append(0)\n",
    "        precision_by_time_af_nf.append(0)\n",
    "        precision_by_time_ne_af.append(0)\n",
    "        precision_by_time_ne_af_nf.append(0)\n",
    "        precision_by_time_gat_af.append(0)\n",
    "        precision_by_time_gat_af_nf.append(0)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "illicit_data = df[(df['label'] == '1') & (df['time_step'] >= 35)]\n",
    "\n",
    "grouped_illicit = illicit_data.groupby('time_step').size()\n",
    "\n",
    "plt.title('Illicit Operations Through Time')\n",
    "\n",
    "ax1.set_xlabel('Time Step')\n",
    "ax1.set_ylabel('# of Illicit Operations')\n",
    "ax1.set_xticks(range(len(grouped_illicit)), grouped_illicit.index, rotation=0)\n",
    "ax1.bar(time_steps, grouped_illicit, width=0.8, edgecolor='lightblue', color='lightblue')\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel('F-1 Score')\n",
    "line_lf, = ax2.plot(time_steps, precision_by_time_lf, color='red', marker='o')\n",
    "line_af, = ax2.plot(time_steps, precision_by_time_af, color='orange', marker='x', label='All Features')\n",
    "line_lf_nf, = ax2.plot(time_steps, precision_by_time_lf_nf, color='magenta', marker='^', label='Local Featuras + Node Features')\n",
    "line_af_nf, = ax2.plot(time_steps, precision_by_time_af_nf, color='cyan', marker='v', label='All Featuras + Node Features')\n",
    "line_ne_af, = ax2.plot(time_steps, precision_by_time_ne_af, color='blue', marker='.', label='Node Embeddings (GCN) + All Featuras')\n",
    "line_ne_af_nf, = ax2.plot(time_steps, precision_by_time_ne_af_nf, color='yellow', marker='D', label='Node Embeddings (GCN) + All Featuras + Node Features')\n",
    "line_gat_af, = ax2.plot(time_steps, precision_by_time_gat_af, color='green', marker='*', label='Node Embeddings (GAT) + All Featuras')\n",
    "line_gat_af_nf, = ax2.plot(time_steps, precision_by_time_gat_af_nf, color='purple', marker='d', label='Node Embeddings (GAT) + All Featuras + Node Features')\n",
    "\n",
    "ax2.legend([line_lf, line_af, line_lf_nf, line_af_nf, line_ne_af, line_ne_af_nf, line_gat_af, line_gat_af_nf], ['Local Features', \n",
    "                                                                       'All Features', \n",
    "                                                                       'Local Featuras + Node Features', \n",
    "                                                                       'All Featuras + Node Features', \n",
    "                                                                       'Node Embeddings + All Featuras',\n",
    "                                                                       'Node Embeddings + All Featuras + Node Features',\n",
    "                                                                       'Node Embeddings (GAT) + All Featuras',\n",
    "                                                                       'Node Embeddings (GAT) + All Featuras + Node Features'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
