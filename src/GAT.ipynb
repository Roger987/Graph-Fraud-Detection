{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09652951-ae33-4589-99cc-f58d9224c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7dba8cc-6cb9-44b3-af4a-19d5d3eb2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 234355/234355 [00:01<00:00, 121145.13it/s]\n"
     ]
    }
   ],
   "source": [
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "\n",
    "# Preprocess the classes DataFrame\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))\n",
    "\n",
    "# Create a mapping for all nodes\n",
    "all_nodes_dict = {tx_id: i for i, tx_id in enumerate(classes['txId'])}\n",
    "\n",
    "# Create edges list with all nodes\n",
    "edges_list = [\n",
    "    (all_nodes_dict[edges['txId1'][i]], all_nodes_dict[edges['txId2'][i]])\n",
    "    for i in tqdm(range(len(edges)))\n",
    "    if edges['txId1'][i] in all_nodes_dict and edges['txId2'][i] in all_nodes_dict\n",
    "]\n",
    "edge_index = torch.tensor(edges_list, dtype=torch.long).T\n",
    "\n",
    "# Convert node features and labels    Parameter to (V) choose features used\n",
    "#node_features = torch.tensor(df.iloc[:, 1:].values, dtype=torch.float)\n",
    "time_step = torch.tensor(df['time_step'].values, dtype=torch.float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.iloc[:, 2:].values)  # Exclude txId and time_step\n",
    "\n",
    "# Combine time_step back with scaled features\n",
    "node_features = torch.cat((time_step.unsqueeze(1), torch.tensor(scaled_features, dtype=torch.float)), dim=1)\n",
    "\n",
    "label_mapping = {'1': 0, '2': 1, 'unknown': -1} \n",
    "labels = torch.tensor(classes['label'].map(label_mapping).values, dtype=torch.long)\n",
    "\n",
    "# Create graph data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5935a2f7-2d2c-4770-bc0d-06a78e2f6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_column_index = 0 \n",
    "time_step = data.x[:, time_step_column_index]\n",
    "\n",
    "train_mask = (time_step >= 1) & (time_step <= 34)\n",
    "test_mask = (time_step >= 35) & (time_step <= 49)\n",
    "\n",
    "train_mask = train_mask.clone().detach().to(torch.bool)\n",
    "test_mask = test_mask.clone().detach().to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ca5205a-d79f-4229-8eff-831d2ede503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (gat): GATConv(166, 128, heads=2)\n",
      "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "2\n",
      "Epoch   0 | Loss: 0.66 | Acc: 29.06%\n",
      "Epoch  10 | Loss: 0.73 | Acc: 71.20%\n",
      "Epoch  20 | Loss: 0.34 | Acc: 81.81%\n",
      "Epoch  30 | Loss: 0.29 | Acc: 82.07%\n",
      "Epoch  40 | Loss: 0.27 | Acc: 86.52%\n",
      "Epoch  50 | Loss: 0.25 | Acc: 85.96%\n",
      "Epoch  60 | Loss: 0.24 | Acc: 87.41%\n",
      "Epoch  70 | Loss: 0.23 | Acc: 87.22%\n",
      "Epoch  80 | Loss: 0.22 | Acc: 87.64%\n",
      "Epoch  90 | Loss: 0.21 | Acc: 88.18%\n",
      "Epoch 100 | Loss: 0.20 | Acc: 88.87%\n",
      "Epoch 110 | Loss: 0.19 | Acc: 89.62%\n",
      "Epoch 120 | Loss: 0.28 | Acc: 81.49%\n",
      "Epoch 130 | Loss: 0.22 | Acc: 87.61%\n",
      "Epoch 140 | Loss: 0.22 | Acc: 85.42%\n",
      "Epoch 150 | Loss: 0.20 | Acc: 88.09%\n",
      "Epoch 160 | Loss: 0.19 | Acc: 90.29%\n",
      "Epoch 170 | Loss: 0.18 | Acc: 89.60%\n",
      "Epoch 180 | Loss: 0.17 | Acc: 90.33%\n",
      "Epoch 190 | Loss: 0.17 | Acc: 90.46%\n",
      "Epoch 200 | Loss: 0.17 | Acc: 90.99%\n",
      "Epoch 210 | Loss: 0.31 | Acc: 87.63%\n",
      "Epoch 220 | Loss: 0.23 | Acc: 91.12%\n",
      "Epoch 230 | Loss: 0.21 | Acc: 87.17%\n",
      "Epoch 240 | Loss: 0.20 | Acc: 90.17%\n",
      "Epoch 250 | Loss: 0.19 | Acc: 89.65%\n"
     ]
    }
   ],
   "source": [
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = 2  # Number of classes (2 in this case)\n",
    "heads = 2\n",
    "#Hyperparameters\n",
    "embeddings_length = 128\n",
    "lr = 0.02\n",
    "weight_decay = 0.001\n",
    "epochs = 251\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, embeddings_length, heads, num_classes):\n",
    "        super().__init__()\n",
    "        self.gat= GATConv(in_channels=in_channels, out_channels=embeddings_length, heads=heads)\n",
    "        self.out = Linear(embeddings_length * heads, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gat(x, edge_index)\n",
    "        z = self.out(h)\n",
    "        return h, z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = 2  # Number of classes (2 in this case)\n",
    "embeddings_length = 128\n",
    "heads = 2\n",
    "model = GAT(num_features, embeddings_length, heads, num_classes)\n",
    "print(model)\n",
    "print(num_classes)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "valid_labels = classes['label'].map(label_mapping)\n",
    "valid_labels = valid_labels[valid_labels != -1]  # Exclude 'unknown'\n",
    "\n",
    "# Compute class weights only for valid labels\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),  # Include only valid classes\n",
    "    y=valid_labels\n",
    ")\n",
    "\n",
    "# Convert to a PyTorch tensor for use in the loss function\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Accuracy calculation function\n",
    "def accuracy(pred_y, y):\n",
    "    return (pred_y == y).sum() / len(y)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    h, z = model(data.x, data.edge_index)  # h: embeddings, z: logits\n",
    "\n",
    "    # Exclude unlabeled nodes from the loss calculation\n",
    "    mask = data.y[train_mask] != -1  \n",
    "    loss = criterion(z[train_mask][mask], data.y[train_mask][mask]) # Compute loss\n",
    "    \n",
    "    loss.backward()                         # Backpropagate\n",
    "    optimizer.step()                        # Update model parameters\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = accuracy(z[train_mask].argmax(dim=1)[mask], data.y[train_mask][mask])  # Calculate accuracy\n",
    "        print(f'Epoch {epoch:>3} | Loss: {loss:.2f} | Acc: {acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c90e62-65cf-412a-9e71-f074bfed34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings, _ = model(data.x, data.edge_index)  # h: embeddings\n",
    "\n",
    "# Ensure alignment of txId and labels with embeddings\n",
    "# The order in `data.x` corresponds to `classes['txId']` due to how `all_nodes_dict` was built\n",
    "aligned_df = pd.DataFrame({\n",
    "    'txId': classes['txId'],  # Use the original node order\n",
    "    'time_step': time_step.cpu().numpy(),  # Extract time_step from the GCN input\n",
    "    'label': classes['label']  # Use the original labels\n",
    "})\n",
    "\n",
    "# Add embeddings\n",
    "embeddings_df = pd.concat([aligned_df, pd.DataFrame(embeddings.cpu().numpy())], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "embeddings_df.to_csv('embeddings_gat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7f663-5560-494d-83a0-05085a110246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
