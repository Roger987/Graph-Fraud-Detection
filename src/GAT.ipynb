{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09652951-ae33-4589-99cc-f58d9224c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dba8cc-6cb9-44b3-af4a-19d5d3eb2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_classes.csv\"\n",
    "edges_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_edgelist.csv\"\n",
    "features_path = \"../elliptic_bitcoin_dataset/modified_elliptic_txs_features.csv\"\n",
    "\n",
    "classes = pd.read_csv(classes_path)\n",
    "edges = pd.read_csv(edges_path)\n",
    "feat_cols = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
    "feats = pd.read_csv(features_path, header=None, names=feat_cols)\n",
    "\n",
    "# Preprocess the classes DataFrame\n",
    "classes.columns = ['txId', 'label']\n",
    "df = classes.set_index('txId').join(feats.set_index('txId'))\n",
    "\n",
    "# Create a mapping for all nodes\n",
    "all_nodes_dict = {tx_id: i for i, tx_id in enumerate(classes['txId'])}\n",
    "\n",
    "# Create edges list with all nodes\n",
    "edges_list = [\n",
    "    (all_nodes_dict[edges['txId1'][i]], all_nodes_dict[edges['txId2'][i]])\n",
    "    for i in tqdm(range(len(edges)))\n",
    "    if edges['txId1'][i] in all_nodes_dict and edges['txId2'][i] in all_nodes_dict\n",
    "]\n",
    "edge_index = torch.tensor(edges_list, dtype=torch.long).T\n",
    "\n",
    "# Convert node features and labels    Parameter to (V) choose features used\n",
    "#node_features = torch.tensor(df.iloc[:, 1:].values, dtype=torch.float)\n",
    "time_step = torch.tensor(df['time_step'].values, dtype=torch.float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.iloc[:, 2:].values)  # Exclude txId and time_step\n",
    "\n",
    "# Combine time_step back with scaled features\n",
    "node_features = torch.cat((time_step.unsqueeze(1), torch.tensor(scaled_features, dtype=torch.float)), dim=1)\n",
    "\n",
    "label_mapping = {'1': 0, '2': 1, 'unknown': -1} \n",
    "labels = torch.tensor(classes['label'].map(label_mapping).values, dtype=torch.long)\n",
    "\n",
    "# Create graph data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "print(device)\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935a2f7-2d2c-4770-bc0d-06a78e2f6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_column_index = 0 \n",
    "time_step = data.x[:, time_step_column_index]\n",
    "\n",
    "train_mask = (time_step >= 1) & (time_step <= 34)\n",
    "test_mask = (time_step >= 35) & (time_step <= 49)\n",
    "\n",
    "train_mask = train_mask.clone().detach().to(torch.bool)\n",
    "test_mask = test_mask.clone().detach().to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5205a-d79f-4229-8eff-831d2ede503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = 2  # Number of classes (2 in this case)\n",
    "heads = 2\n",
    "#Hyperparameters\n",
    "embeddings_length = 128\n",
    "lr = 0.02\n",
    "weight_decay = 0.001\n",
    "epochs = 201\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, embeddings_length, heads, num_classes):\n",
    "        super().__init__()\n",
    "        self.gat= GATConv(in_channels=in_channels, out_channels=embeddings_length, heads=heads)\n",
    "        self.out = Linear(embeddings_length * heads, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gat(x, edge_index)\n",
    "        z = self.out(h)\n",
    "        return h, z\n",
    "\n",
    "# Initialize the model\n",
    "num_features = data.x.shape[1]  # Number of features (columns in x)\n",
    "num_classes = 2  # Number of classes (2 in this case)\n",
    "embeddings_length = 128\n",
    "heads = 2\n",
    "model = GAT(num_features, embeddings_length, heads, num_classes).to(device)\n",
    "print(model)\n",
    "print(num_classes)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "valid_labels = classes['label'].map(label_mapping)\n",
    "valid_labels = valid_labels[valid_labels != -1]  # Exclude 'unknown'\n",
    "\n",
    "# Compute class weights only for valid labels\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),  # Include only valid classes\n",
    "    y=valid_labels\n",
    ")\n",
    "\n",
    "# Convert to a PyTorch tensor for use in the loss function\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor).to(device)\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Accuracy calculation function\n",
    "def accuracy(pred_y, y):\n",
    "    return (pred_y == y).sum() / len(y)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    h, z = model(data.x, data.edge_index)  # h: embeddings, z: logits\n",
    "\n",
    "    # Exclude unlabeled nodes from the loss calculation\n",
    "    mask = data.y[train_mask] != -1  \n",
    "    loss = criterion(z[train_mask][mask], data.y[train_mask][mask]) # Compute loss\n",
    "    \n",
    "    loss.backward()                         # Backpropagate\n",
    "    optimizer.step()                        # Update model parameters\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = accuracy(z[train_mask].argmax(dim=1)[mask], data.y[train_mask][mask])  # Calculate accuracy\n",
    "        print(f'Epoch {epoch:>3} | Loss: {loss:.2f} | Acc: {acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c90e62-65cf-412a-9e71-f074bfed34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings, _ = model(data.x, data.edge_index)  # h: embeddings\n",
    "\n",
    "# Ensure alignment of txId and labels with embeddings\n",
    "# The order in `data.x` corresponds to `classes['txId']` due to how `all_nodes_dict` was built\n",
    "aligned_df = pd.DataFrame({\n",
    "    'txId': classes['txId'],  # Use the original node order\n",
    "    'time_step': time_step.cpu().numpy(),  # Extract time_step from the GCN input\n",
    "    'label': classes['label']  # Use the original labels\n",
    "})\n",
    "\n",
    "# Add embeddings\n",
    "embeddings_df = pd.concat([aligned_df, pd.DataFrame(embeddings.cpu().numpy())], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "embeddings_df.to_csv('../data/embeddings_gat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7f663-5560-494d-83a0-05085a110246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
